[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "水産海洋データ解析演習",
    "section": "",
    "text": "To learn more about Quarto websites visit https://quarto.org/docs/websites.\n\nsessionInfo()\n\nR version 4.2.1 (2022-06-23)\nPlatform: x86_64-pc-linux-gnu (64-bit)\nRunning under: Debian GNU/Linux 11 (bullseye)\n\nMatrix products: default\nBLAS:   /usr/lib/x86_64-linux-gnu/atlas/libblas.so.3.10.3\nLAPACK: /usr/lib/x86_64-linux-gnu/atlas/liblapack.so.3.10.3\n\nlocale:\n [1] LC_CTYPE=en_US.utf8        LC_NUMERIC=C              \n [3] LC_TIME=ja_JP.UTF-8        LC_COLLATE=en_US.utf8     \n [5] LC_MONETARY=ja_JP.UTF-8    LC_MESSAGES=en_US.utf8    \n [7] LC_PAPER=ja_JP.UTF-8       LC_NAME=C                 \n [9] LC_ADDRESS=C               LC_TELEPHONE=C            \n[11] LC_MEASUREMENT=ja_JP.UTF-8 LC_IDENTIFICATION=C       \n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.5.4 compiler_4.2.1    magrittr_2.0.3    fastmap_1.1.0    \n [5] cli_3.4.0         tools_4.2.1       htmltools_0.5.3   yaml_2.3.5       \n [9] stringi_1.7.8     rmarkdown_2.14    knitr_1.39        stringr_1.4.0    \n[13] xfun_0.32         digest_0.6.29     jsonlite_1.8.0    rlang_1.0.5      \n[17] evaluate_0.16"
  },
  {
    "objectID": "part01.html",
    "href": "part01.html",
    "title": "R の基本操作",
    "section": "",
    "text": "と RStudio はインストール済み\nにおける単純計算方法はできる\nFira Code プログラミング用等幅フォントを使っています。\nこのフォントにより、演算子は見やすくなります\n\nたとえば\n\n<- は < と - の合字 (リガチャー, ligature) です (ALT + -)\n|> は | と > の合字です (CTRL + SHIFT + M)\n<= は < と = の合字です\n!= は ! と = の合字です\n\nこの資料は R version 4.2.1 (2022-06-23) 環境で作りました。Quarto で作成しました。日本語はめちゃくちゃかもしれないので、気になるなら訂正案を送ってください。"
  },
  {
    "objectID": "part01.html#代入演算子-assignment-operator-とベクトル-vector-とは",
    "href": "part01.html#代入演算子-assignment-operator-とベクトル-vector-とは",
    "title": "R の基本操作",
    "section": "代入演算子 (assignment operator) とベクトル (vector) とは",
    "text": "代入演算子 (assignment operator) とベクトル (vector) とは\n\n代入は = か <- (< と -) です。伝統的に使われる代入は <- ですが、私は = を使っています。\n左辺は変数名、右辺は値です。\n\n\n# 二種類の代入と c() 関数\na = 4.2\nb <- 5.0\nc(a, b)\n\n[1] 4.2 5.0\n\n\n\nc() は渡された引数を結合します。\n# の後から続く文字列はコードとして実行されません。実行されない文書はコメントと呼びます。\n\n\n(a + b) * c(a, b)\n\n[1] 38.64 46.00\n\n\n\nR はベクトル処理という実行機構が特徴的です。\n上のコードは (a + b) \\times a と (a + b) \\times b を求めています。\n\nRStudio の場合 <- は ALT + - のショートカットを定義しています。"
  },
  {
    "objectID": "part01.html#r-の主なデータタイプとデータ構造",
    "href": "part01.html#r-の主なデータタイプとデータ構造",
    "title": "R の基本操作",
    "section": "R の主なデータタイプとデータ構造",
    "text": "R の主なデータタイプとデータ構造\n\n整数 integer\n実数 double, numeric\n複素数 complex number\n時系列 time-series (POSIX)\n文字列 character\n論理値 logical\n因子 factor\nベクトル　vector\n配列 array, matrix\nリスト list\nテーブル（データフレーム） dataframe"
  },
  {
    "objectID": "part01.html#データの作り方",
    "href": "part01.html#データの作り方",
    "title": "R の基本操作",
    "section": "データの作り方",
    "text": "データの作り方\nベクトル\n\na = c(10.3, 20.2, 30.1)\nb = c(\"rabbit\", \"cat\", \"mouse\", \"dog\")\nd = c(TRUE, FALSE, T)\ne = factor(c(\"nagasaki\", \"kagoshima\", \"fukuoka\"))\n\nリスト\nベクトルの長さは異なってもいい。 ここでは、リストの要素名を指定しました。\n\nz1 = list(\"A\" = a, \"B\"= b, \"D\" = d, \"E\" = e)\n\nデータフレーム\nベクトルの長さを揃える必要がある。 ここではb[1:3]をbに渡すことで、変数名を指定しました。\n\nz2 = data.frame(a, b = b[1:3], d, e)"
  },
  {
    "objectID": "part01.html#リストの構造を確認しよう",
    "href": "part01.html#リストの構造を確認しよう",
    "title": "R の基本操作",
    "section": "リストの構造を確認しよう",
    "text": "リストの構造を確認しよう\nRオブジェクトの構造 (structure) は str() で確認します。\n\nstr(z1)\n\nList of 4\n $ A: num [1:3] 10.3 20.2 30.1\n $ B: chr [1:4] \"rabbit\" \"cat\" \"mouse\" \"dog\"\n $ D: logi [1:3] TRUE FALSE TRUE\n $ E: Factor w/ 3 levels \"fukuoka\",\"kagoshima\",..: 3 2 1"
  },
  {
    "objectID": "part01.html#リストからデータを抽出する",
    "href": "part01.html#リストからデータを抽出する",
    "title": "R の基本操作",
    "section": "リストからデータを抽出する",
    "text": "リストからデータを抽出する\nリストの要素は次のように抽出できます。\n\nz1$A\n\n[1] 10.3 20.2 30.1\n\n\nリストからの抽出方法は $ 以外に, [ や [[ でもできます。\n\nz1[c(\"A\", \"D\")]\nz1[c(1,4)]\nz1[[2]]\nz1[[c(2,3)]]\nz1[[2]][c(1,2)]"
  },
  {
    "objectID": "part01.html#データフレームの構造を確認しよう",
    "href": "part01.html#データフレームの構造を確認しよう",
    "title": "R の基本操作",
    "section": "データフレームの構造を確認しよう",
    "text": "データフレームの構造を確認しよう\n\nstr(z2)\n\n'data.frame':   3 obs. of  4 variables:\n $ a: num  10.3 20.2 30.1\n $ b: chr  \"rabbit\" \"cat\" \"mouse\"\n $ d: logi  TRUE FALSE TRUE\n $ e: Factor w/ 3 levels \"fukuoka\",\"kagoshima\",..: 3 2 1\n\n\nリストと似ていますが、そもそもデータフレームはリストです。 つまり、リストと同じように操作できます。\n\nz2$a\n\n[1] 10.3 20.2 30.1\n\n\n\nz2[c(\"a\", \"d\")]\nz2[c(1, 4)]\nz2[[2]]\nz2[[c(2,3)]]\nz2[[2]][c(1,2)]"
  },
  {
    "objectID": "part01.html#比較演算",
    "href": "part01.html#比較演算",
    "title": "R の基本操作",
    "section": "比較演算",
    "text": "比較演算\n\n比較に使う論理演算子：&（論理積 AND）, | （論理和 OR）, !（否定 NOT）\n\n\nA = c(5, 3, 2)\nB = c(5, 2, 1)\n\n# 論理積\n(A[1] > B[1]) & (A[1] == B[1])\n\n[1] FALSE\n\n# 論理和\n(A[1] > B[1]) | (A[1] == B[1])\n\n[1] TRUE\n\n\n\n# 否定と論理積\n!(A[1] > B[1]) & (A[1] == B[1])\n\n[1] TRUE\n\n# 否定と論理和\n(A[1] < B[2]) | !(A[1] == B[1])\n\n[1] FALSE"
  },
  {
    "objectID": "part01.html#比較演算を使ったデータの抽出",
    "href": "part01.html#比較演算を使ったデータの抽出",
    "title": "R の基本操作",
    "section": "比較演算を使ったデータの抽出",
    "text": "比較演算を使ったデータの抽出\n\na = c(10.3, 20.2, 30.1)\nb = c(\"rabbit\", \"cat\", \"mouse\")\nd = c(TRUE, FALSE, T)\ne = factor(c(\"nagasaki\", \n             \"kagoshima\", \n             \"fukuoka\"))\nZ = data.frame(a, b, d, e)\nZ[Z$a > 20, ]\n\n     a     b     d         e\n2 20.2   cat FALSE kagoshima\n3 30.1 mouse  TRUE   fukuoka\n\n\n\nZ[Z$a > 10 & Z$a < 20.2, ]\n\n     a      b    d        e\n1 10.3 rabbit TRUE nagasaki\n\nZ[Z$a > 10 & Z$a <= 20.2, ]\n\n     a      b     d         e\n1 10.3 rabbit  TRUE  nagasaki\n2 20.2    cat FALSE kagoshima\n\nZ[identical(Z$a, 20) | !Z$d, ]\n\n     a   b     d         e\n2 20.2 cat FALSE kagoshima"
  },
  {
    "objectID": "part01.html#重要-数値を比較について",
    "href": "part01.html#重要-数値を比較について",
    "title": "R の基本操作",
    "section": "重要! 数値を比較について",
    "text": "重要! 数値を比較について\nパソコンは 2 進数で計算しているので、数値は正確ではない！\nたとえば：\n\n0.2 * 0.2 / 0.2 == 0.2 # = と =\n\n[1] FALSE\n\n\n数値の比較をする場合は all.equal() を使いましょう。\n\nall.equal(0.2 * 0.2 / 0.2, 0.2, tolerance = 0) # 上のコードと同じ\n\n[1] \"Mean relative difference: 1.387779e-16\"\n\nall.equal(0.2 * 0.2 / 0.2, 0.2, tolerance = .Machine$double.eps) # 機械誤差を考慮した比較\n\n[1] TRUE\n\n\n\nちなみに比較用記号は <, >, >= (> と =), <= (< と =), != (! と =), == (= と =)　です。"
  },
  {
    "objectID": "part02.html",
    "href": "part02.html",
    "title": "R 関数の基本",
    "section": "",
    "text": "関数をつくることにより、 での作業がとても楽になります。 コードを繰り返して使うなら関数をつくりましょう。\n\n\nR の関数に 2 つのパーツがあります。\n\nArguments: 引数\nCode block: 関数のコードは {} の間に納めます。\n\n\nhello = function(x) {\n  if(!is.character(x)) {\n    stop(\"Please provide a character string.\")\n  }\n  sprintf(\"Hello %s!\", x)\n}\n\nhello(214)\n\nError in hello(214): Please provide a character string.\n\nhello(\"Yukio\")\n\n[1] \"Hello Yukio!\"\n\n\n\n\n\n関数の中に作ったものは、関数の中にしか存在しない。\n\n\n\n\nsumofsquare = function(x) {\n  ss = (x - mean(x))^2 # 関数の外から見れない\n  ssq = sum(ss) # 関数の外から見れない\n  ssq # 関数の外に返す\n}\ndata = sample(1:10, 5, replace = TRUE)\ndata\n\n[1]  7  6 10  7  4\n\nvalue = sumofsquare(data)\nvalue\n\n[1] 18.8\n\n\n\n\n\nところが、関数は外の環境に存在するものは見れます。 このように関数を作ると、バグを起こしやすいので、注意。\n\nsumofsquare = function(x) {\n  ss = (s - mean(s))^2 # s は関数の外にあるが、関数の引数ではない\n  ssq = sum(ss) # 関数の外から見れない\n  ssq # 関数の外に返す\n}\ns = sample(100:1000, 5, replace = TRUE)\ns\n\n[1] 169 291 862 713 721\n\ndata = sample(1:10, 5, replace = TRUE)\ndata\n\n[1] 5 7 9 7 3\n\nvalue = sumofsquare(data)\nvalue　# これは s の平方和です。\n\n[1] 365388.8\n\n\n\n\n\n関数は次のようにもかけます。 \\(x){...} はラムダ式 (lambda expression) とも呼ばれています。\n\nadd_one = \\(x) { x + 1}\nadd_one(5)\n\n[1] 6\n\n\n無名関数をつくるときに便利な書き方です。\n\n# どちれも無名関数ですが、２つ目の関数がはラムダ式です。\nz = 1:5\nsapply(z, FUN = function(s){s^2})\n\n[1]  1  4  9 16 25\n\nsapply(z, FUN = \\(s){s^2})\n\n[1]  1  4  9 16 25"
  },
  {
    "objectID": "part03.html",
    "href": "part03.html",
    "title": "Tidyverse",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.3.6      ✔ purrr   0.3.4 \n✔ tibble  3.1.8      ✔ dplyr   1.0.10\n✔ tidyr   1.2.0      ✔ stringr 1.4.0 \n✔ readr   2.1.2      ✔ forcats 0.5.1 \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()"
  },
  {
    "objectID": "part03.html#tidyverse-1",
    "href": "part03.html#tidyverse-1",
    "title": "Tidyverse",
    "section": "tidyverse",
    "text": "tidyverse\ntidyverse はメタパッケージなので、library(tidyverse) を実行すると次の 8 つのパッケージが読み込まれます。\n\ndplyr：データの変形・加工\nforcats：factor() 因子が使いやすくなります\nggplot2：データの可視化・作図\npurrr ：関数型プログラミング\nreadr ：CSV、TSVデータの読み込み\nstringr ：文字列の操作が楽になる\ntibble ：データフレームの操作が楽になる\ntidyr ：データをタイディ (tidy) にして操作しやすくなる\n\ntidyverse の概念をもっと知りたい方はtidyverse のマニフェストを読みましょう。"
  },
  {
    "objectID": "part03.html#tibble-には-list-列を入れられる",
    "href": "part03.html#tibble-には-list-列を入れられる",
    "title": "Tidyverse",
    "section": "tibble には list 列を入れられる",
    "text": "tibble には list 列を入れられる\nちょっと高度の方法ですが, list を変数の要素として記録できます。\n\na1 = list(1,5,1,3,5,1)\na2 = list(2,3,5,2)\na3 = list(\"A\",\"b\",\"E\")\ntibble(a = 1:3, values = list(a1, a2, a3))\n\n# A tibble: 3 × 2\n      a values    \n  <int> <list>    \n1     1 <list [6]>\n2     2 <list [4]>\n3     3 <list [3]>\n\n\nvalues 列は list の list ですね。"
  },
  {
    "objectID": "part03.html#列名変数名について",
    "href": "part03.html#列名変数名について",
    "title": "Tidyverse",
    "section": "列名・変数名について",
    "text": "列名・変数名について\ndata.frame() は無効な変数名を自動的に変更します。\n\ndata.frame(`1 name` = 1) |> names()\n\n[1] \"X1.name\"\n\n\ntibble() はそのままにしてくれます。\n\ntibble(`1 name` = 1) |> names()\n\n[1] \"1 name\"\n\n\n\n\n\ndata.frame()の場合 * 有効な変数名：文字または、ドット(.)と文字から始まる文字列。変数名に使用できるものは文字、数字、ドットとアンダースコア (_) だけです。 * 無効な変数名の例：2021FY, 2021 FY, 2020-FY, FY-2021 は自動的に X2021FY, X2021.FY, X2020.FY, FY.2021 に変更されます。\ntibble()の場合 * 変数名はそのまま使えますが、使うときは ` ` （バクチック）に囲んでください。\nところが! どうしても data.frame() に無効な変数名を使いたいのであれば、check.names = F を渡してください。\n\ndata.frame(`1 name` = 1, check.names = FALSE) |> names()\n\n[1] \"1 name\""
  },
  {
    "objectID": "part03.html#引数を連続的に使える",
    "href": "part03.html#引数を連続的に使える",
    "title": "Tidyverse",
    "section": "引数を連続的に使える",
    "text": "引数を連続的に使える\ntibble()はこのように, 計算処理をしながらデータフレームを構築できます。\n\ntibble(x = 1:4, `x^2` = x^2, `sqrt(x)` = sqrt(x))\n\n# A tibble: 4 × 3\n      x `x^2` `sqrt(x)`\n  <int> <dbl>     <dbl>\n1     1     1      1   \n2     2     4      1.41\n3     3     9      1.73\n4     4    16      2"
  },
  {
    "objectID": "part03.html#ベクトルをリサイクルしない",
    "href": "part03.html#ベクトルをリサイクルしない",
    "title": "Tidyverse",
    "section": "ベクトルをリサイクルしない",
    "text": "ベクトルをリサイクルしない\n二つのベクトルの長さが異なるときに, データフレームを作ると, 小さいほうのベクトルは先頭から繰り返して使われます。ただし長いベクトルの要素数は短いベクトルの要素数で除算できる必要があります。\n\nx = 1:4\ny = 1:8\ndata.frame(x, y)\n\n  x y\n1 1 1\n2 2 2\n3 3 3\n4 4 4\n5 1 5\n6 2 6\n7 3 7\n8 4 8\n\n\nところが, この機能はデータ解析時にバグの原因になります。tibble()はベクトルのリサイクルはできません。\n\nx = 1:4\ny = 1:8\ntibble(x, y)\n\nError:\n! Tibble columns must have compatible sizes.\n• Size 4: Existing data.\n• Size 8: Column at position 2.\nℹ Only values of size one are recycled."
  },
  {
    "objectID": "part03.html#io-関係の関数",
    "href": "part03.html#io-関係の関数",
    "title": "Tidyverse",
    "section": "I/O 関係の関数",
    "text": "I/O 関係の関数\n読み込み関数\n\nread_delim()：一般性の高い関数, 区切りの指定が必要\nread_csv()：コンマ区切りフィアルの読み込み（csv ファイル）\nread_table()：ホワイトスペース区切りファイルの読み込み（タブ・スペース区切りファイル）\nread_rds()：R オブジェクトの読み込み\n\n書き出し関数\n\nwrite_delim()：一般性の高い関数, 区切りの指定が必要\nwrite_csv()：コンマ区切りフィアルの書き出し\nwrite_table()：ホワイトスペース区切りファイルの書き出し（タブ・スペース区切りファイル）\nwrite_rds()：R オブジェクトの書き出し\nggsave(): ggplot2 でつくった図を書き出し"
  },
  {
    "objectID": "part03.html#read_csv-の重要な引数",
    "href": "part03.html#read_csv-の重要な引数",
    "title": "Tidyverse",
    "section": "read_csv() の重要な引数",
    "text": "read_csv() の重要な引数\n\nfile：パスとファイル名\ncol_names = TRUE：TRUEのとき, 1行目は列名として使う, FALSE のときは列名を自動的に作成する, 文字列ベクトルを渡せば読み込み中に列名を付けられます\ncol_types = NULL：列のデータ型を指定できるが NULL のときは関数に任せる\ncomment = \"\"：コメント記号を指定し, コメント記号後の文字を無視する\nskip = 0 先頭から無視する行数\nlocale：ロケール（地域の設定）\nn_max = Inf：読み込む行数、デフォルトは全ての行数"
  },
  {
    "objectID": "part03.html#read_csvの使い方",
    "href": "part03.html#read_csvの使い方",
    "title": "Tidyverse",
    "section": "read_csv()の使い方",
    "text": "read_csv()の使い方\nread_csv()\n\nrabbits = read_csv(\"Assignment_06_Dataset01.csv\")\nrabbits\n\n\n\nRows: 37 Columns: 2\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): host\ndbl (1): scutum.width\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n# A tibble: 37 × 2\n   host    scutum.width\n   <chr>          <dbl>\n 1 Rabbit1          380\n 2 Rabbit1          376\n 3 Rabbit1          360\n 4 Rabbit1          368\n 5 Rabbit1          372\n 6 Rabbit1          366\n 7 Rabbit1          374\n 8 Rabbit1          382\n 9 Rabbit2          350\n10 Rabbit2          356\n# … with 27 more rows"
  },
  {
    "objectID": "part03.html#readxl-パッケージ",
    "href": "part03.html#readxl-パッケージ",
    "title": "Tidyverse",
    "section": "readxl パッケージ",
    "text": "readxl パッケージ\nreadxl は Microsoft Excelファイルの読み込みに使えるパッケージです。\n\nlibrary(readxl)\n\nファイルの読み込みには read_excel() を使いますが、研究室では read_xlsx() もよく使います。 read_excel() は read_xlsx() のラッパーです。 使い方は全くおなじです。\n重要： エクセルでデータの管理をした場合エクセルのオートコレクト機能によってデータがかってに変換されるので気をつけましょう。遺伝子の名前のオートコレクトによく問題が発生すると報告されています。とくに Excel と Google Sheets のオートコレクトはアグレッシブです。Abeysooriya et al. 2021. PLOS Computational Biology。"
  },
  {
    "objectID": "part03.html#read_excel-の主な引数",
    "href": "part03.html#read_excel-の主な引数",
    "title": "Tidyverse",
    "section": "read_excel() の主な引数",
    "text": "read_excel() の主な引数\n\npath：パスとファイル名\nsheet = NULL：読み込むシート名またはシートインデックス\nrange = NULL：読み込む範囲, 例えば “B3:D8” または, “Data!B3:D8”\ncol_names = TRUE：1行目を列名として使う論理値\ncol_types = NULL：読み込む列のデータ型を指定できます (デフォルトは guess)\nna = \"\"：欠損値の定義, 空セルは欠損値とされます\nskip = 0：無視する行数\nn_max = Inf：読み込む最大行数"
  },
  {
    "objectID": "part03.html#read_excel-の使用例１",
    "href": "part03.html#read_excel-の使用例１",
    "title": "Tidyverse",
    "section": "read_excel() の使用例（１）",
    "text": "read_excel() の使用例（１）\n最初のシート (sheet = 1) の先頭から1行無視して (skip = 1) データを読み込む。\n\nfilename = \"Table 2.xlsx\"\nexceldata = read_excel(filename, sheet = 1, skip = 1)\nexceldata\n\n\n\nNew names:\n• `WT (˚C)` -> `WT (˚C)...2`\n• `S.D.**` -> `S.D.**...3`\n• `` -> `...4`\n• `WT (˚C)` -> `WT (˚C)...5`\n• `S.D.**` -> `S.D.**...6`\n\n\n# A tibble: 12 × 6\n   Month `WT (˚C)...2` `S.D.**...3` ...4  `WT (˚C)...5` `S.D.**...6`\n   <chr>         <dbl>        <dbl> <lgl>         <dbl>        <dbl>\n 1 Jan.           21.1        0.446 NA             16.5        0.428\n 2 Feb.           21.3        0.441 NA             16.3        0.483\n 3 Mar.           21.5        0.470 NA             16.5        0.579\n 4 Apr.           21.8        0.554 NA             18.3        1.27 \n 5 May            23.4        0.726 NA             21.1        1.08 \n 6 Jun.           25.5        1.20  NA             22.9        1.02 \n 7 Jul.           28.6        0.491 NA             26.6        1.15 \n 8 Aug.           28.8        0.546 NA             28.5        0.470\n 9 Sep.           28.5        0.375 NA             27.7        0.794\n10 Oct.           26.6        0.893 NA             24.4        1.05 \n11 Nov.           24.7        0.516 NA             21.6        0.928\n12 Dec.           22.8        0.720 NA             19.1        0.893"
  },
  {
    "objectID": "part03.html#read_excel-の使用例２",
    "href": "part03.html#read_excel-の使用例２",
    "title": "Tidyverse",
    "section": "read_excel() の使用例（２）",
    "text": "read_excel() の使用例（２）\n先程のように読み込むと、不都合な変数名に変換されました。次は、変数名も指定して読み込みます。\n\nfilename = \"Table 2.xlsx\"\ncol_names = c(\"month\", \"temperature1\", \"sd1\", \"empty\",\"temperature2\", \"sd2\")\nexceldata = read_excel(filename, sheet = 1, skip = 2, col_name = col_names)\nexceldata |> print(n = 4)\n\n\n\n# A tibble: 12 × 6\n  month temperature1   sd1 empty temperature2   sd2\n  <chr>        <dbl> <dbl> <lgl>        <dbl> <dbl>\n1 Jan.          21.1 0.446 NA            16.5 0.428\n2 Feb.          21.3 0.441 NA            16.3 0.483\n3 Mar.          21.5 0.470 NA            16.5 0.579\n4 Apr.          21.8 0.554 NA            18.3 1.27 \n# … with 8 more rows\n\n\nシートの２行目には変数名が記録されているので、skip = 2 を渡しました。"
  },
  {
    "objectID": "part03.html#データの出力",
    "href": "part03.html#データの出力",
    "title": "Tidyverse",
    "section": "データの出力",
    "text": "データの出力\nCSVファイルの出力\n\nfname = \"table2_output.csv\"\nexceldata |> write_csv(file = fname) # 文字コードは UTF-8 です。\n\nエクセルにCSVファイルを読み込んで文字化けした場合、write_excel_csv()を試してみてください。\n\nexceldata |> write_excel_csv(file = fname)\n\nRDSファイルの出力\nRのオブジェクトをバイナリファイルとして保存したい場合は write_rds() を使います。\n\nfname = \"table2_output.rds\"\nexceldata |> write_rds(file = fname)"
  },
  {
    "objectID": "part04.html",
    "href": "part04.html",
    "title": "データの操作",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.3.6      ✔ purrr   0.3.4 \n✔ tibble  3.1.8      ✔ dplyr   1.0.10\n✔ tidyr   1.2.0      ✔ stringr 1.4.0 \n✔ readr   2.1.2      ✔ forcats 0.5.1 \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()"
  },
  {
    "objectID": "part04.html#理想的なデータ構造",
    "href": "part04.html#理想的なデータ構造",
    "title": "データの操作",
    "section": "理想的なデータ構造",
    "text": "理想的なデータ構造\n\n1 行 = 1 観測値\n1 列 = 1 変数"
  },
  {
    "objectID": "part04.html#データ加工操作用関数",
    "href": "part04.html#データ加工操作用関数",
    "title": "データの操作",
    "section": "データ加工・操作用関数",
    "text": "データ加工・操作用関数\nデータの結合 (mutating join)\nx, y, by は関数の引数です。by で指定したキー（変数名）が一致するように行を合わせることができる。\n\nfull_join(x, y, by)：全ての x と y 行と列を結合する。\ninner_join(x, y, by)：x と y で共通する行と列を結合する。\nleft_join(x, y, by)：左側（）第 1 引数のtibble に y の変数を追加する。\nright_join(x, y, by)：右側（）第 2 引数のtibble に x の変数を追加する。\n\nデータの結合 (join)\n\nbind_cols()：渡したtibbleを横に結合する（行数が異なったらエラーが発生する）。\nbind_rows()：渡した tibble を立てに結合する（一致する変数名を合わせてくれます）。"
  },
  {
    "objectID": "part04.html#mutating-join-のつかいかた",
    "href": "part04.html#mutating-join-のつかいかた",
    "title": "データの操作",
    "section": "mutating join のつかいかた",
    "text": "mutating join のつかいかた\n\nX = tibble(x = c(\"A\", \"B\", \"C\", \"G\"), y = c(NA, rnorm(3, mean = 5)))\nY = tibble(x = c(\"A\", \"C\", \"D\", \"E\"), z = c(rpois(3, lambda = 5), NA))\n\n\nX\n\n# A tibble: 4 × 2\n  x         y\n  <chr> <dbl>\n1 A     NA   \n2 B      5.21\n3 C      6.81\n4 G      6.13\n\n\n\nY\n\n# A tibble: 4 × 2\n  x         z\n  <chr> <int>\n1 A         9\n2 C         8\n3 D         5\n4 E        NA\n\n\n\nfull_join(X,Y, by = \"x\")\n\n# A tibble: 6 × 3\n  x         y     z\n  <chr> <dbl> <int>\n1 A     NA        9\n2 B      5.21    NA\n3 C      6.81     8\n4 G      6.13    NA\n5 D     NA        5\n6 E     NA       NA\n\n\n\ninner_join(X, Y, by = \"x\")\n\n# A tibble: 2 × 3\n  x         y     z\n  <chr> <dbl> <int>\n1 A     NA        9\n2 C      6.81     8\n\n\n\nleft_join(X, Y, by = \"x\")\n\n# A tibble: 4 × 3\n  x         y     z\n  <chr> <dbl> <int>\n1 A     NA        9\n2 B      5.21    NA\n3 C      6.81     8\n4 G      6.13    NA\n\n\n\nright_join(X, Y, by = \"x\")\n\n# A tibble: 4 × 3\n  x         y     z\n  <chr> <dbl> <int>\n1 A     NA        9\n2 C      6.81     8\n3 D     NA        5\n4 E     NA       NA\n\n\n\nbind_rows(X, Y)\n\n# A tibble: 8 × 3\n  x         y     z\n  <chr> <dbl> <int>\n1 A     NA       NA\n2 B      5.21    NA\n3 C      6.81    NA\n4 G      6.13    NA\n5 A     NA        9\n6 C     NA        8\n7 D     NA        5\n8 E     NA       NA\n\n\n\nbind_rows(\"X\" = X, \"Y\" = Y, .id = \"origin\")\n\n# A tibble: 8 × 4\n  origin x         y     z\n  <chr>  <chr> <dbl> <int>\n1 X      A     NA       NA\n2 X      B      5.21    NA\n3 X      C      6.81    NA\n4 X      G      6.13    NA\n5 Y      A     NA        9\n6 Y      C     NA        8\n7 Y      D     NA        5\n8 Y      E     NA       NA\n\n\n\nbind_cols(X, Y)\n\nNew names:\n• `x` -> `x...1`\n• `x` -> `x...3`\n\n\n# A tibble: 4 × 4\n  x...1     y x...3     z\n  <chr> <dbl> <chr> <int>\n1 A     NA    A         9\n2 B      5.21 C         8\n3 C      6.81 D         5\n4 G      6.13 E        NA"
  },
  {
    "objectID": "part04.html#行と列の加工操作用関数",
    "href": "part04.html#行と列の加工操作用関数",
    "title": "データの操作",
    "section": "行と列の加工・操作用関数",
    "text": "行と列の加工・操作用関数\n列における操作\n\nmutate()：既存の変数の書き換えや変数の追加する\nselect()：既存の変数を選らぶ\nrename()：既存の変数の名前を変える\npull()：既存の変数をリストとして抽出する\n`relocate()``：指定した列の位置を変える\n\n行における操作\n\nfilter()：条件を満たした行を返す\ndistinct()：指定した変数から重複している行を外す\nslice()：指定した行インデックスを返す\narrange()：指定した列の昇順で行を並べ替える"
  },
  {
    "objectID": "part04.html#列の加工",
    "href": "part04.html#列の加工",
    "title": "データの操作",
    "section": "列の加工",
    "text": "列の加工\n\niris |> as_tibble() |> mutate(P2 = Petal.Length^2)\n\n# A tibble: 150 × 6\n   Sepal.Length Sepal.Width Petal.Length Petal.Width Species    P2\n          <dbl>       <dbl>        <dbl>       <dbl> <fct>   <dbl>\n 1          5.1         3.5          1.4         0.2 setosa   1.96\n 2          4.9         3            1.4         0.2 setosa   1.96\n 3          4.7         3.2          1.3         0.2 setosa   1.69\n 4          4.6         3.1          1.5         0.2 setosa   2.25\n 5          5           3.6          1.4         0.2 setosa   1.96\n 6          5.4         3.9          1.7         0.4 setosa   2.89\n 7          4.6         3.4          1.4         0.3 setosa   1.96\n 8          5           3.4          1.5         0.2 setosa   2.25\n 9          4.4         2.9          1.4         0.2 setosa   1.96\n10          4.9         3.1          1.5         0.1 setosa   2.25\n# … with 140 more rows\n\n\n\niris |> as_tibble() |> select(Species, Petal.Length)\n\n# A tibble: 150 × 2\n   Species Petal.Length\n   <fct>          <dbl>\n 1 setosa           1.4\n 2 setosa           1.4\n 3 setosa           1.3\n 4 setosa           1.5\n 5 setosa           1.4\n 6 setosa           1.7\n 7 setosa           1.4\n 8 setosa           1.5\n 9 setosa           1.4\n10 setosa           1.5\n# … with 140 more rows\n\n\n\niris |> as_tibble() |> select(matches(\"Length\"))\n\n# A tibble: 150 × 2\n   Sepal.Length Petal.Length\n          <dbl>        <dbl>\n 1          5.1          1.4\n 2          4.9          1.4\n 3          4.7          1.3\n 4          4.6          1.5\n 5          5            1.4\n 6          5.4          1.7\n 7          4.6          1.4\n 8          5            1.5\n 9          4.4          1.4\n10          4.9          1.5\n# … with 140 more rows\n\n\n\niris |> as_tibble() |> rename(PL = Petal.Length)\n\n# A tibble: 150 × 5\n   Sepal.Length Sepal.Width    PL Petal.Width Species\n          <dbl>       <dbl> <dbl>       <dbl> <fct>  \n 1          5.1         3.5   1.4         0.2 setosa \n 2          4.9         3     1.4         0.2 setosa \n 3          4.7         3.2   1.3         0.2 setosa \n 4          4.6         3.1   1.5         0.2 setosa \n 5          5           3.6   1.4         0.2 setosa \n 6          5.4         3.9   1.7         0.4 setosa \n 7          4.6         3.4   1.4         0.3 setosa \n 8          5           3.4   1.5         0.2 setosa \n 9          4.4         2.9   1.4         0.2 setosa \n10          4.9         3.1   1.5         0.1 setosa \n# … with 140 more rows\n\n\n\niris |> as_tibble() |> \n  rename_with(~str_replace_all(.x, \"[(a-z.)]\", \"\"), .cols = matches(\"(Pet)|(Sep)\"))\n\n# A tibble: 150 × 5\n      SL    SW    PL    PW Species\n   <dbl> <dbl> <dbl> <dbl> <fct>  \n 1   5.1   3.5   1.4   0.2 setosa \n 2   4.9   3     1.4   0.2 setosa \n 3   4.7   3.2   1.3   0.2 setosa \n 4   4.6   3.1   1.5   0.2 setosa \n 5   5     3.6   1.4   0.2 setosa \n 6   5.4   3.9   1.7   0.4 setosa \n 7   4.6   3.4   1.4   0.3 setosa \n 8   5     3.4   1.5   0.2 setosa \n 9   4.4   2.9   1.4   0.2 setosa \n10   4.9   3.1   1.5   0.1 setosa \n# … with 140 more rows\n\n\n\niris |> as_tibble() |> pull(Species)\n\n  [1] setosa     setosa     setosa     setosa     setosa     setosa    \n  [7] setosa     setosa     setosa     setosa     setosa     setosa    \n [13] setosa     setosa     setosa     setosa     setosa     setosa    \n [19] setosa     setosa     setosa     setosa     setosa     setosa    \n [25] setosa     setosa     setosa     setosa     setosa     setosa    \n [31] setosa     setosa     setosa     setosa     setosa     setosa    \n [37] setosa     setosa     setosa     setosa     setosa     setosa    \n [43] setosa     setosa     setosa     setosa     setosa     setosa    \n [49] setosa     setosa     versicolor versicolor versicolor versicolor\n [55] versicolor versicolor versicolor versicolor versicolor versicolor\n [61] versicolor versicolor versicolor versicolor versicolor versicolor\n [67] versicolor versicolor versicolor versicolor versicolor versicolor\n [73] versicolor versicolor versicolor versicolor versicolor versicolor\n [79] versicolor versicolor versicolor versicolor versicolor versicolor\n [85] versicolor versicolor versicolor versicolor versicolor versicolor\n [91] versicolor versicolor versicolor versicolor versicolor versicolor\n [97] versicolor versicolor versicolor versicolor virginica  virginica \n[103] virginica  virginica  virginica  virginica  virginica  virginica \n[109] virginica  virginica  virginica  virginica  virginica  virginica \n[115] virginica  virginica  virginica  virginica  virginica  virginica \n[121] virginica  virginica  virginica  virginica  virginica  virginica \n[127] virginica  virginica  virginica  virginica  virginica  virginica \n[133] virginica  virginica  virginica  virginica  virginica  virginica \n[139] virginica  virginica  virginica  virginica  virginica  virginica \n[145] virginica  virginica  virginica  virginica  virginica  virginica \nLevels: setosa versicolor virginica\n\n\n\niris |> as_tibble() |> relocate(Species, .before = \"Sepal.Length\")\n\n# A tibble: 150 × 5\n   Species Sepal.Length Sepal.Width Petal.Length Petal.Width\n   <fct>          <dbl>       <dbl>        <dbl>       <dbl>\n 1 setosa           5.1         3.5          1.4         0.2\n 2 setosa           4.9         3            1.4         0.2\n 3 setosa           4.7         3.2          1.3         0.2\n 4 setosa           4.6         3.1          1.5         0.2\n 5 setosa           5           3.6          1.4         0.2\n 6 setosa           5.4         3.9          1.7         0.4\n 7 setosa           4.6         3.4          1.4         0.3\n 8 setosa           5           3.4          1.5         0.2\n 9 setosa           4.4         2.9          1.4         0.2\n10 setosa           4.9         3.1          1.5         0.1\n# … with 140 more rows\n\n\n\niris |> as_tibble() |> relocate(Species, matches(\"Length\"), .before = \"Sepal.Length\")\n\n# A tibble: 150 × 5\n   Species Sepal.Length Petal.Length Sepal.Width Petal.Width\n   <fct>          <dbl>        <dbl>       <dbl>       <dbl>\n 1 setosa           5.1          1.4         3.5         0.2\n 2 setosa           4.9          1.4         3           0.2\n 3 setosa           4.7          1.3         3.2         0.2\n 4 setosa           4.6          1.5         3.1         0.2\n 5 setosa           5            1.4         3.6         0.2\n 6 setosa           5.4          1.7         3.9         0.4\n 7 setosa           4.6          1.4         3.4         0.3\n 8 setosa           5            1.5         3.4         0.2\n 9 setosa           4.4          1.4         2.9         0.2\n10 setosa           4.9          1.5         3.1         0.1\n# … with 140 more rows"
  },
  {
    "objectID": "part04.html#行の加工",
    "href": "part04.html#行の加工",
    "title": "データの操作",
    "section": "行の加工",
    "text": "行の加工\n\niris |> as_tibble() |> filter(str_detect(Species, \"versicolor\"))\n\n# A tibble: 50 × 5\n   Sepal.Length Sepal.Width Petal.Length Petal.Width Species   \n          <dbl>       <dbl>        <dbl>       <dbl> <fct>     \n 1          7           3.2          4.7         1.4 versicolor\n 2          6.4         3.2          4.5         1.5 versicolor\n 3          6.9         3.1          4.9         1.5 versicolor\n 4          5.5         2.3          4           1.3 versicolor\n 5          6.5         2.8          4.6         1.5 versicolor\n 6          5.7         2.8          4.5         1.3 versicolor\n 7          6.3         3.3          4.7         1.6 versicolor\n 8          4.9         2.4          3.3         1   versicolor\n 9          6.6         2.9          4.6         1.3 versicolor\n10          5.2         2.7          3.9         1.4 versicolor\n# … with 40 more rows\n\n\n\niris |> as_tibble() |> filter(Petal.Length > 6 & Sepal.Length > 7.5)\n\n# A tibble: 6 × 5\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species  \n         <dbl>       <dbl>        <dbl>       <dbl> <fct>    \n1          7.6         3            6.6         2.1 virginica\n2          7.7         3.8          6.7         2.2 virginica\n3          7.7         2.6          6.9         2.3 virginica\n4          7.7         2.8          6.7         2   virginica\n5          7.9         3.8          6.4         2   virginica\n6          7.7         3            6.1         2.3 virginica\n\n\n\niris |> as_tibble() |> distinct(Species)\n\n# A tibble: 3 × 1\n  Species   \n  <fct>     \n1 setosa    \n2 versicolor\n3 virginica \n\n\n\niris |> as_tibble() |> distinct(Petal.Length, .keep_all = T)\n\n# A tibble: 43 × 5\n   Sepal.Length Sepal.Width Petal.Length Petal.Width Species   \n          <dbl>       <dbl>        <dbl>       <dbl> <fct>     \n 1          5.1         3.5          1.4         0.2 setosa    \n 2          4.7         3.2          1.3         0.2 setosa    \n 3          4.6         3.1          1.5         0.2 setosa    \n 4          5.4         3.9          1.7         0.4 setosa    \n 5          4.8         3.4          1.6         0.2 setosa    \n 6          4.3         3            1.1         0.1 setosa    \n 7          5.8         4            1.2         0.2 setosa    \n 8          4.6         3.6          1           0.2 setosa    \n 9          4.8         3.4          1.9         0.2 setosa    \n10          7           3.2          4.7         1.4 versicolor\n# … with 33 more rows\n\n\n\niris |> as_tibble() |> slice(1:5)\n\n# A tibble: 5 × 5\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n         <dbl>       <dbl>        <dbl>       <dbl> <fct>  \n1          5.1         3.5          1.4         0.2 setosa \n2          4.9         3            1.4         0.2 setosa \n3          4.7         3.2          1.3         0.2 setosa \n4          4.6         3.1          1.5         0.2 setosa \n5          5           3.6          1.4         0.2 setosa \n\niris |> as_tibble() |> slice_head(n = 2)\n\n# A tibble: 2 × 5\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n         <dbl>       <dbl>        <dbl>       <dbl> <fct>  \n1          5.1         3.5          1.4         0.2 setosa \n2          4.9         3            1.4         0.2 setosa \n\niris |> as_tibble() |> slice_tail(n = 2)\n\n# A tibble: 2 × 5\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species  \n         <dbl>       <dbl>        <dbl>       <dbl> <fct>    \n1          6.2         3.4          5.4         2.3 virginica\n2          5.9         3            5.1         1.8 virginica\n\n\n\niris |> as_tibble() |> slice_min(Petal.Length)\n\n# A tibble: 1 × 5\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n         <dbl>       <dbl>        <dbl>       <dbl> <fct>  \n1          4.6         3.6            1         0.2 setosa \n\niris |> as_tibble() |> slice_max(Petal.Length)\n\n# A tibble: 1 × 5\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species  \n         <dbl>       <dbl>        <dbl>       <dbl> <fct>    \n1          7.7         2.6          6.9         2.3 virginica\n\niris |> as_tibble() |> slice_sample(n = 3)\n\n# A tibble: 3 × 5\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species   \n         <dbl>       <dbl>        <dbl>       <dbl> <fct>     \n1          7.7         2.8          6.7         2   virginica \n2          7.2         3            5.8         1.6 virginica \n3          5.7         2.6          3.5         1   versicolor\n\n\n\niris |> as_tibble() |> arrange(Sepal.Length)\n\n# A tibble: 150 × 5\n   Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n          <dbl>       <dbl>        <dbl>       <dbl> <fct>  \n 1          4.3         3            1.1         0.1 setosa \n 2          4.4         2.9          1.4         0.2 setosa \n 3          4.4         3            1.3         0.2 setosa \n 4          4.4         3.2          1.3         0.2 setosa \n 5          4.5         2.3          1.3         0.3 setosa \n 6          4.6         3.1          1.5         0.2 setosa \n 7          4.6         3.4          1.4         0.3 setosa \n 8          4.6         3.6          1           0.2 setosa \n 9          4.6         3.2          1.4         0.2 setosa \n10          4.7         3.2          1.3         0.2 setosa \n# … with 140 more rows\n\n\n\niris |> as_tibble() |> \n  arrange(desc(Sepal.Length), desc(Sepal.Width))\n\n# A tibble: 150 × 5\n   Sepal.Length Sepal.Width Petal.Length Petal.Width Species  \n          <dbl>       <dbl>        <dbl>       <dbl> <fct>    \n 1          7.9         3.8          6.4         2   virginica\n 2          7.7         3.8          6.7         2.2 virginica\n 3          7.7         3            6.1         2.3 virginica\n 4          7.7         2.8          6.7         2   virginica\n 5          7.7         2.6          6.9         2.3 virginica\n 6          7.6         3            6.6         2.1 virginica\n 7          7.4         2.8          6.1         1.9 virginica\n 8          7.3         2.9          6.3         1.8 virginica\n 9          7.2         3.6          6.1         2.5 virginica\n10          7.2         3.2          6           1.8 virginica\n# … with 140 more rows"
  },
  {
    "objectID": "part04.html#グループ化ネストに関する関数",
    "href": "part04.html#グループ化ネストに関する関数",
    "title": "データの操作",
    "section": "グループ化・ネストに関する関数",
    "text": "グループ化・ネストに関する関数\n\ngroup_by()：tibble をグループ化する\ngroup_nest()：グループ化した tibble をネスト（入れ子）する\nnest()：渡した列をネストする\nunnest()：ネストされている列を展開（アンネスト）する\ngroup_map()：グループ化した tibble に関数を適応して、リストを返す\ngroup_modify()：グループ化した tibble に関数を適応して、tibble を返す"
  },
  {
    "objectID": "part04.html#tibble-のグループ化",
    "href": "part04.html#tibble-のグループ化",
    "title": "データの操作",
    "section": "tibble のグループ化",
    "text": "tibble のグループ化\n\niris |> as_tibble() |> select(1:3)\n\n# A tibble: 150 × 3\n   Sepal.Length Sepal.Width Petal.Length\n          <dbl>       <dbl>        <dbl>\n 1          5.1         3.5          1.4\n 2          4.9         3            1.4\n 3          4.7         3.2          1.3\n 4          4.6         3.1          1.5\n 5          5           3.6          1.4\n 6          5.4         3.9          1.7\n 7          4.6         3.4          1.4\n 8          5           3.4          1.5\n 9          4.4         2.9          1.4\n10          4.9         3.1          1.5\n# … with 140 more rows\n\n\n\niris |> as_tibble() |> group_by(Species) |> select(1:3)\n\nAdding missing grouping variables: `Species`\n\n\n# A tibble: 150 × 4\n# Groups:   Species [3]\n   Species Sepal.Length Sepal.Width Petal.Length\n   <fct>          <dbl>       <dbl>        <dbl>\n 1 setosa           5.1         3.5          1.4\n 2 setosa           4.9         3            1.4\n 3 setosa           4.7         3.2          1.3\n 4 setosa           4.6         3.1          1.5\n 5 setosa           5           3.6          1.4\n 6 setosa           5.4         3.9          1.7\n 7 setosa           4.6         3.4          1.4\n 8 setosa           5           3.4          1.5\n 9 setosa           4.4         2.9          1.4\n10 setosa           4.9         3.1          1.5\n# … with 140 more rows\n\n\n\niris |> as_tibble() |> group_nest(Species)\n\n# A tibble: 3 × 2\n  Species                  data\n  <fct>      <list<tibble[,4]>>\n1 setosa               [50 × 4]\n2 versicolor           [50 × 4]\n3 virginica            [50 × 4]\n\n\n\niris |> as_tibble() |> nest(data = matches(\"Length|Width\"))\n\n# A tibble: 3 × 2\n  Species    data             \n  <fct>      <list>           \n1 setosa     <tibble [50 × 4]>\n2 versicolor <tibble [50 × 4]>\n3 virginica  <tibble [50 × 4]>\n\n\n\niris |> as_tibble() |> group_nest(Species) |> unnest(data)\n\n# A tibble: 150 × 5\n   Species Sepal.Length Sepal.Width Petal.Length Petal.Width\n   <fct>          <dbl>       <dbl>        <dbl>       <dbl>\n 1 setosa           5.1         3.5          1.4         0.2\n 2 setosa           4.9         3            1.4         0.2\n 3 setosa           4.7         3.2          1.3         0.2\n 4 setosa           4.6         3.1          1.5         0.2\n 5 setosa           5           3.6          1.4         0.2\n 6 setosa           5.4         3.9          1.7         0.4\n 7 setosa           4.6         3.4          1.4         0.3\n 8 setosa           5           3.4          1.5         0.2\n 9 setosa           4.4         2.9          1.4         0.2\n10 setosa           4.9         3.1          1.5         0.1\n# … with 140 more rows\n\n\n\niris |> as_tibble() |> group_by(Species) |> group_map(~head(.x, n = 2))\n\n[[1]]\n# A tibble: 2 × 4\n  Sepal.Length Sepal.Width Petal.Length Petal.Width\n         <dbl>       <dbl>        <dbl>       <dbl>\n1          5.1         3.5          1.4         0.2\n2          4.9         3            1.4         0.2\n\n[[2]]\n# A tibble: 2 × 4\n  Sepal.Length Sepal.Width Petal.Length Petal.Width\n         <dbl>       <dbl>        <dbl>       <dbl>\n1          7           3.2          4.7         1.4\n2          6.4         3.2          4.5         1.5\n\n[[3]]\n# A tibble: 2 × 4\n  Sepal.Length Sepal.Width Petal.Length Petal.Width\n         <dbl>       <dbl>        <dbl>       <dbl>\n1          6.3         3.3          6           2.5\n2          5.8         2.7          5.1         1.9\n\n\n\niris |> as_tibble() |> group_by(Species) |> group_modify(~head(.x, n = 2))\n\n# A tibble: 6 × 5\n# Groups:   Species [3]\n  Species    Sepal.Length Sepal.Width Petal.Length Petal.Width\n  <fct>             <dbl>       <dbl>        <dbl>       <dbl>\n1 setosa              5.1         3.5          1.4         0.2\n2 setosa              4.9         3            1.4         0.2\n3 versicolor          7           3.2          4.7         1.4\n4 versicolor          6.4         3.2          4.5         1.5\n5 virginica           6.3         3.3          6           2.5\n6 virginica           5.8         2.7          5.1         1.9"
  },
  {
    "objectID": "part04.html#その他の関数",
    "href": "part04.html#その他の関数",
    "title": "データの操作",
    "section": "その他の関数",
    "text": "その他の関数\n\ndrop_na()：NA（欠損値）を含む行を削除\nreplace_na()：NAを他の値と書き換える\nfill()：NAを直前の値で埋める\nseparate()：文字列の変数を任意の区切りで複数変数に分裂する\nunite()：複数の変数を任意の区切りで 1 列にまとめる\n\n\nX\n\n# A tibble: 4 × 2\n  x         y\n  <chr> <dbl>\n1 A     NA   \n2 B      5.21\n3 C      6.81\n4 G      6.13\n\n\n\nX |> drop_na()\n\n# A tibble: 3 × 2\n  x         y\n  <chr> <dbl>\n1 B      5.21\n2 C      6.81\n3 G      6.13\n\n\n\nX |> replace_na(list(x = \"Z\", y = 0))\n\n# A tibble: 4 × 2\n  x         y\n  <chr> <dbl>\n1 A      0   \n2 B      5.21\n3 C      6.81\n4 G      6.13\n\n\n\nX |> mutate(y = replace_na(y, 0))\n\n# A tibble: 4 × 2\n  x         y\n  <chr> <dbl>\n1 A      0   \n2 B      5.21\n3 C      6.81\n4 G      6.13\n\n\n\nY |> fill(z)\n\n# A tibble: 4 × 2\n  x         z\n  <chr> <int>\n1 A         9\n2 C         8\n3 D         5\n4 E         5\n\n\n\ntibble(x = c(NA, \"Iris.setosa\", \"Iris.virginica\", \"Iris.versicolor\")) |> \n  separate(x, into = c(\"Genus\", \"Species\"))\n\n# A tibble: 4 × 2\n  Genus Species   \n  <chr> <chr>     \n1 <NA>  <NA>      \n2 Iris  setosa    \n3 Iris  virginica \n4 Iris  versicolor\n\n\n\ntibble(x = rep(\"Iris\", 3), y = c(\"setosa\", \"virginica\", \"versicolor\")) |> \n  unite(Species, x, y, sep = \"_\")\n\n# A tibble: 3 × 1\n  Species        \n  <chr>          \n1 Iris_setosa    \n2 Iris_virginica \n3 Iris_versicolor"
  },
  {
    "objectID": "part04.html#ピボットtibbleを変形する関数",
    "href": "part04.html#ピボットtibbleを変形する関数",
    "title": "データの操作",
    "section": "ピボット・tibbleを変形する関数",
    "text": "ピボット・tibbleを変形する関数\n\npivot_longer()：tibble を wide format （横広）から long format （縦長）に変える\npivot_wider()：tibble をlong format から wide format に変える\n\n\n重要な引数\npivot_longer()\n\ncols：動かす変数\nnames_to：動かした変数の名前の移動先\nvalues_to：動かした変数の値の移動先\nnames_transform：移動先の変数のタイプを変換\n\npivot_wider()\n\nid_cols：行（値）を区別するための列名\nnames_from：移動先の列名になる変数\nvalues_from：移動したい値\nvalues_fill：存在しない要素の埋め込み方法\nvalues_fn：行の区別ができないときの処理（デフォルトはリスト）"
  },
  {
    "objectID": "part04.html#pivot_longer-の使い方",
    "href": "part04.html#pivot_longer-の使い方",
    "title": "データの操作",
    "section": "pivot_longer() の使い方",
    "text": "pivot_longer() の使い方\n\nrelig_income |> as_tibble()\n\n# A tibble: 18 × 11\n   religion      `<$10k` $10-2…¹ $20-3…² $30-4…³ $40-5…⁴ $50-7…⁵ $75-1…⁶ $100-…⁷\n   <chr>           <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n 1 Agnostic           27      34      60      81      76     137     122     109\n 2 Atheist            12      27      37      52      35      70      73      59\n 3 Buddhist           27      21      30      34      33      58      62      39\n 4 Catholic          418     617     732     670     638    1116     949     792\n 5 Don’t know/r…      15      14      15      11      10      35      21      17\n 6 Evangelical …     575     869    1064     982     881    1486     949     723\n 7 Hindu               1       9       7       9      11      34      47      48\n 8 Historically…     228     244     236     238     197     223     131      81\n 9 Jehovah's Wi…      20      27      24      24      21      30      15      11\n10 Jewish             19      19      25      25      30      95      69      87\n11 Mainline Prot     289     495     619     655     651    1107     939     753\n12 Mormon             29      40      48      51      56     112      85      49\n13 Muslim              6       7       9      10       9      23      16       8\n14 Orthodox           13      17      23      32      32      47      38      42\n15 Other Christ…       9       7      11      13      13      14      18      14\n16 Other Faiths       20      33      40      46      49      63      46      40\n17 Other World …       5       2       3       4       2       7       3       4\n18 Unaffiliated      217     299     374     365     341     528     407     321\n# … with 2 more variables: `>150k` <dbl>, `Don't know/refused` <dbl>, and\n#   abbreviated variable names ¹​`$10-20k`, ²​`$20-30k`, ³​`$30-40k`, ⁴​`$40-50k`,\n#   ⁵​`$50-75k`, ⁶​`$75-100k`, ⁷​`$100-150k`\n\n\n\nrelig_income |> as_tibble() |> \npivot_longer(!religion, names_to = \"income\", values_to = \"count\")\n\n# A tibble: 180 × 3\n   religion income             count\n   <chr>    <chr>              <dbl>\n 1 Agnostic <$10k                 27\n 2 Agnostic $10-20k               34\n 3 Agnostic $20-30k               60\n 4 Agnostic $30-40k               81\n 5 Agnostic $40-50k               76\n 6 Agnostic $50-75k              137\n 7 Agnostic $75-100k             122\n 8 Agnostic $100-150k            109\n 9 Agnostic >150k                 84\n10 Agnostic Don't know/refused    96\n# … with 170 more rows\n\n\n\nbillboard |> as_tibble()\n\n# A tibble: 317 × 79\n   artist track date.ent…¹   wk1   wk2   wk3   wk4   wk5   wk6   wk7   wk8   wk9\n   <chr>  <chr> <date>     <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>\n 1 2 Pac  Baby… 2000-02-26    87    82    72    77    87    94    99    NA    NA\n 2 2Ge+h… The … 2000-09-02    91    87    92    NA    NA    NA    NA    NA    NA\n 3 3 Doo… Kryp… 2000-04-08    81    70    68    67    66    57    54    53    51\n 4 3 Doo… Loser 2000-10-21    76    76    72    69    67    65    55    59    62\n 5 504 B… Wobb… 2000-04-15    57    34    25    17    17    31    36    49    53\n 6 98^0   Give… 2000-08-19    51    39    34    26    26    19     2     2     3\n 7 A*Tee… Danc… 2000-07-08    97    97    96    95   100    NA    NA    NA    NA\n 8 Aaliy… I Do… 2000-01-29    84    62    51    41    38    35    35    38    38\n 9 Aaliy… Try … 2000-03-18    59    53    38    28    21    18    16    14    12\n10 Adams… Open… 2000-08-26    76    76    74    69    68    67    61    58    57\n# … with 307 more rows, 67 more variables: wk10 <dbl>, wk11 <dbl>, wk12 <dbl>,\n#   wk13 <dbl>, wk14 <dbl>, wk15 <dbl>, wk16 <dbl>, wk17 <dbl>, wk18 <dbl>,\n#   wk19 <dbl>, wk20 <dbl>, wk21 <dbl>, wk22 <dbl>, wk23 <dbl>, wk24 <dbl>,\n#   wk25 <dbl>, wk26 <dbl>, wk27 <dbl>, wk28 <dbl>, wk29 <dbl>, wk30 <dbl>,\n#   wk31 <dbl>, wk32 <dbl>, wk33 <dbl>, wk34 <dbl>, wk35 <dbl>, wk36 <dbl>,\n#   wk37 <dbl>, wk38 <dbl>, wk39 <dbl>, wk40 <dbl>, wk41 <dbl>, wk42 <dbl>,\n#   wk43 <dbl>, wk44 <dbl>, wk45 <dbl>, wk46 <dbl>, wk47 <dbl>, wk48 <dbl>, …\n\n\n\nbillboard |> as_tibble() |> \n  pivot_longer(col = starts_with(\"wk\"),\n               names_to = \"week\", names_prefix = \"wk\",\n               values_to = \"rank\", values_drop_na = TRUE)\n\n# A tibble: 5,307 × 5\n   artist  track                   date.entered week   rank\n   <chr>   <chr>                   <date>       <chr> <dbl>\n 1 2 Pac   Baby Don't Cry (Keep... 2000-02-26   1        87\n 2 2 Pac   Baby Don't Cry (Keep... 2000-02-26   2        82\n 3 2 Pac   Baby Don't Cry (Keep... 2000-02-26   3        72\n 4 2 Pac   Baby Don't Cry (Keep... 2000-02-26   4        77\n 5 2 Pac   Baby Don't Cry (Keep... 2000-02-26   5        87\n 6 2 Pac   Baby Don't Cry (Keep... 2000-02-26   6        94\n 7 2 Pac   Baby Don't Cry (Keep... 2000-02-26   7        99\n 8 2Ge+her The Hardest Part Of ... 2000-09-02   1        91\n 9 2Ge+her The Hardest Part Of ... 2000-09-02   2        87\n10 2Ge+her The Hardest Part Of ... 2000-09-02   3        92\n# … with 5,297 more rows\n\n\n\nwho |> as_tibble()\n\n# A tibble: 7,240 × 60\n   country     iso2  iso3   year new_s…¹ new_s…² new_s…³ new_s…⁴ new_s…⁵ new_s…⁶\n   <chr>       <chr> <chr> <int>   <int>   <int>   <int>   <int>   <int>   <int>\n 1 Afghanistan AF    AFG    1980      NA      NA      NA      NA      NA      NA\n 2 Afghanistan AF    AFG    1981      NA      NA      NA      NA      NA      NA\n 3 Afghanistan AF    AFG    1982      NA      NA      NA      NA      NA      NA\n 4 Afghanistan AF    AFG    1983      NA      NA      NA      NA      NA      NA\n 5 Afghanistan AF    AFG    1984      NA      NA      NA      NA      NA      NA\n 6 Afghanistan AF    AFG    1985      NA      NA      NA      NA      NA      NA\n 7 Afghanistan AF    AFG    1986      NA      NA      NA      NA      NA      NA\n 8 Afghanistan AF    AFG    1987      NA      NA      NA      NA      NA      NA\n 9 Afghanistan AF    AFG    1988      NA      NA      NA      NA      NA      NA\n10 Afghanistan AF    AFG    1989      NA      NA      NA      NA      NA      NA\n# … with 7,230 more rows, 50 more variables: new_sp_m65 <int>,\n#   new_sp_f014 <int>, new_sp_f1524 <int>, new_sp_f2534 <int>,\n#   new_sp_f3544 <int>, new_sp_f4554 <int>, new_sp_f5564 <int>,\n#   new_sp_f65 <int>, new_sn_m014 <int>, new_sn_m1524 <int>,\n#   new_sn_m2534 <int>, new_sn_m3544 <int>, new_sn_m4554 <int>,\n#   new_sn_m5564 <int>, new_sn_m65 <int>, new_sn_f014 <int>,\n#   new_sn_f1524 <int>, new_sn_f2534 <int>, new_sn_f3544 <int>, …\n\n\n\nwho %>% as_tibble() |>\n  pivot_longer(cols = new_sp_m014:newrel_f65,\n               names_to = c(\"diagnosis\", \"gender\", \"age\"),\n               names_pattern = \"new_?(.*)_(.)(.*)\",\n               values_to = \"count\", values_drop_na = TRUE)\n\n# A tibble: 76,046 × 8\n   country     iso2  iso3   year diagnosis gender age   count\n   <chr>       <chr> <chr> <int> <chr>     <chr>  <chr> <int>\n 1 Afghanistan AF    AFG    1997 sp        m      014       0\n 2 Afghanistan AF    AFG    1997 sp        m      1524     10\n 3 Afghanistan AF    AFG    1997 sp        m      2534      6\n 4 Afghanistan AF    AFG    1997 sp        m      3544      3\n 5 Afghanistan AF    AFG    1997 sp        m      4554      5\n 6 Afghanistan AF    AFG    1997 sp        m      5564      2\n 7 Afghanistan AF    AFG    1997 sp        m      65        0\n 8 Afghanistan AF    AFG    1997 sp        f      014       5\n 9 Afghanistan AF    AFG    1997 sp        f      1524     38\n10 Afghanistan AF    AFG    1997 sp        f      2534     36\n# … with 76,036 more rows\n\n\n\nanscombe |> as_tibble()\n\n# A tibble: 11 × 8\n      x1    x2    x3    x4    y1    y2    y3    y4\n   <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>\n 1    10    10    10     8  8.04  9.14  7.46  6.58\n 2     8     8     8     8  6.95  8.14  6.77  5.76\n 3    13    13    13     8  7.58  8.74 12.7   7.71\n 4     9     9     9     8  8.81  8.77  7.11  8.84\n 5    11    11    11     8  8.33  9.26  7.81  8.47\n 6    14    14    14     8  9.96  8.1   8.84  7.04\n 7     6     6     6     8  7.24  6.13  6.08  5.25\n 8     4     4     4    19  4.26  3.1   5.39 12.5 \n 9    12    12    12     8 10.8   9.13  8.15  5.56\n10     7     7     7     8  4.82  7.26  6.42  7.91\n11     5     5     5     8  5.68  4.74  5.73  6.89\n\n\n\nanscombe %>% as_tibble() |> \n pivot_longer(everything(), names_to = c(\".value\", \"set\"), names_pattern = \"(.)(.)\"\n )\n\n# A tibble: 44 × 3\n   set       x     y\n   <chr> <dbl> <dbl>\n 1 1        10  8.04\n 2 2        10  9.14\n 3 3        10  7.46\n 4 4         8  6.58\n 5 1         8  6.95\n 6 2         8  8.14\n 7 3         8  6.77\n 8 4         8  5.76\n 9 1        13  7.58\n10 2        13  8.74\n# … with 34 more rows"
  },
  {
    "objectID": "part04.html#pivot_wider-の使い方",
    "href": "part04.html#pivot_wider-の使い方",
    "title": "データの操作",
    "section": "pivot_wider() の使い方",
    "text": "pivot_wider() の使い方\n\nfish_encounters\n\n# A tibble: 114 × 3\n   fish  station  seen\n   <fct> <fct>   <int>\n 1 4842  Release     1\n 2 4842  I80_1       1\n 3 4842  Lisbon      1\n 4 4842  Rstr        1\n 5 4842  Base_TD     1\n 6 4842  BCE         1\n 7 4842  BCW         1\n 8 4842  BCE2        1\n 9 4842  BCW2        1\n10 4842  MAE         1\n# … with 104 more rows\n\n\n\nfish_encounters |> as_tibble() |> \n  pivot_wider(names_from = station, values_from = seen)\n\n# A tibble: 19 × 12\n   fish  Release I80_1 Lisbon  Rstr Base_TD   BCE   BCW  BCE2  BCW2   MAE   MAW\n   <fct>   <int> <int>  <int> <int>   <int> <int> <int> <int> <int> <int> <int>\n 1 4842        1     1      1     1       1     1     1     1     1     1     1\n 2 4843        1     1      1     1       1     1     1     1     1     1     1\n 3 4844        1     1      1     1       1     1     1     1     1     1     1\n 4 4845        1     1      1     1       1    NA    NA    NA    NA    NA    NA\n 5 4847        1     1      1    NA      NA    NA    NA    NA    NA    NA    NA\n 6 4848        1     1      1     1      NA    NA    NA    NA    NA    NA    NA\n 7 4849        1     1     NA    NA      NA    NA    NA    NA    NA    NA    NA\n 8 4850        1     1     NA     1       1     1     1    NA    NA    NA    NA\n 9 4851        1     1     NA    NA      NA    NA    NA    NA    NA    NA    NA\n10 4854        1     1     NA    NA      NA    NA    NA    NA    NA    NA    NA\n11 4855        1     1      1     1       1    NA    NA    NA    NA    NA    NA\n12 4857        1     1      1     1       1     1     1     1     1    NA    NA\n13 4858        1     1      1     1       1     1     1     1     1     1     1\n14 4859        1     1      1     1       1    NA    NA    NA    NA    NA    NA\n15 4861        1     1      1     1       1     1     1     1     1     1     1\n16 4862        1     1      1     1       1     1     1     1     1    NA    NA\n17 4863        1     1     NA    NA      NA    NA    NA    NA    NA    NA    NA\n18 4864        1     1     NA    NA      NA    NA    NA    NA    NA    NA    NA\n19 4865        1     1      1    NA      NA    NA    NA    NA    NA    NA    NA\n\n\n\nfish_encounters\n\n# A tibble: 114 × 3\n   fish  station  seen\n   <fct> <fct>   <int>\n 1 4842  Release     1\n 2 4842  I80_1       1\n 3 4842  Lisbon      1\n 4 4842  Rstr        1\n 5 4842  Base_TD     1\n 6 4842  BCE         1\n 7 4842  BCW         1\n 8 4842  BCE2        1\n 9 4842  BCW2        1\n10 4842  MAE         1\n# … with 104 more rows\n\n\n\n# 存在しない組み合わせの要素を埋める\nfish_encounters |>  as_tibble() |> \n  pivot_wider(names_from = station, values_from = seen, values_fill = 0)\n\n# A tibble: 19 × 12\n   fish  Release I80_1 Lisbon  Rstr Base_TD   BCE   BCW  BCE2  BCW2   MAE   MAW\n   <fct>   <int> <int>  <int> <int>   <int> <int> <int> <int> <int> <int> <int>\n 1 4842        1     1      1     1       1     1     1     1     1     1     1\n 2 4843        1     1      1     1       1     1     1     1     1     1     1\n 3 4844        1     1      1     1       1     1     1     1     1     1     1\n 4 4845        1     1      1     1       1     0     0     0     0     0     0\n 5 4847        1     1      1     0       0     0     0     0     0     0     0\n 6 4848        1     1      1     1       0     0     0     0     0     0     0\n 7 4849        1     1      0     0       0     0     0     0     0     0     0\n 8 4850        1     1      0     1       1     1     1     0     0     0     0\n 9 4851        1     1      0     0       0     0     0     0     0     0     0\n10 4854        1     1      0     0       0     0     0     0     0     0     0\n11 4855        1     1      1     1       1     0     0     0     0     0     0\n12 4857        1     1      1     1       1     1     1     1     1     0     0\n13 4858        1     1      1     1       1     1     1     1     1     1     1\n14 4859        1     1      1     1       1     0     0     0     0     0     0\n15 4861        1     1      1     1       1     1     1     1     1     1     1\n16 4862        1     1      1     1       1     1     1     1     1     0     0\n17 4863        1     1      0     0       0     0     0     0     0     0     0\n18 4864        1     1      0     0       0     0     0     0     0     0     0\n19 4865        1     1      1     0       0     0     0     0     0     0     0\n\n\n\nus_rent_income |> as_tibble()\n\n# A tibble: 104 × 5\n   GEOID NAME       variable estimate   moe\n   <chr> <chr>      <chr>       <dbl> <dbl>\n 1 01    Alabama    income      24476   136\n 2 01    Alabama    rent          747     3\n 3 02    Alaska     income      32940   508\n 4 02    Alaska     rent         1200    13\n 5 04    Arizona    income      27517   148\n 6 04    Arizona    rent          972     4\n 7 05    Arkansas   income      23789   165\n 8 05    Arkansas   rent          709     5\n 9 06    California income      29454   109\n10 06    California rent         1358     3\n# … with 94 more rows\n\n\n\nus_rent_income |> as_tibble() |> \n  pivot_wider(names_from = variable, values_from = c(estimate, moe))\n\n# A tibble: 52 × 6\n   GEOID NAME                 estimate_income estimate_rent moe_income moe_rent\n   <chr> <chr>                          <dbl>         <dbl>      <dbl>    <dbl>\n 1 01    Alabama                        24476           747        136        3\n 2 02    Alaska                         32940          1200        508       13\n 3 04    Arizona                        27517           972        148        4\n 4 05    Arkansas                       23789           709        165        5\n 5 06    California                     29454          1358        109        3\n 6 08    Colorado                       32401          1125        109        5\n 7 09    Connecticut                    35326          1123        195        5\n 8 10    Delaware                       31560          1076        247       10\n 9 11    District of Columbia           43198          1424        681       17\n10 12    Florida                        25952          1077         70        3\n# … with 42 more rows\n\n# us_rent_income  |> as_tibble() |> \n#   pivot_wider(names_from = variable,\n#               names_sep = \".\",\n#               values_from = c(estimate, moe))\n\n# us_rent_income  |> as_tibble() |> \n#   pivot_wider(names_from = variable,\n#               names_glue = \"{variable}_{.value}\",\n#               values_from = c(estimate, moe))\n\n\nwarpbreaks |> as_tibble()\n\n# A tibble: 54 × 3\n   breaks wool  tension\n    <dbl> <fct> <fct>  \n 1     26 A     L      \n 2     30 A     L      \n 3     54 A     L      \n 4     25 A     L      \n 5     70 A     L      \n 6     52 A     L      \n 7     51 A     L      \n 8     26 A     L      \n 9     67 A     L      \n10     18 A     M      \n# … with 44 more rows\n\n\n\nwarpbreaks |> as_tibble() |> \n  pivot_wider(names_from = wool,\n              values_from = breaks)\n\nWarning: Values from `breaks` are not uniquely identified; output will contain list-cols.\n* Use `values_fn = list` to suppress this warning.\n* Use `values_fn = {summary_fun}` to summarise duplicates.\n* Use the following dplyr code to identify duplicates.\n  {data} %>%\n    dplyr::group_by(tension, wool) %>%\n    dplyr::summarise(n = dplyr::n(), .groups = \"drop\") %>%\n    dplyr::filter(n > 1L)\n\n\n# A tibble: 3 × 3\n  tension A         B        \n  <fct>   <list>    <list>   \n1 L       <dbl [9]> <dbl [9]>\n2 M       <dbl [9]> <dbl [9]>\n3 H       <dbl [9]> <dbl [9]>\n\n\n\nwarpbreaks |> as_tibble()\n\n# A tibble: 54 × 3\n   breaks wool  tension\n    <dbl> <fct> <fct>  \n 1     26 A     L      \n 2     30 A     L      \n 3     54 A     L      \n 4     25 A     L      \n 5     70 A     L      \n 6     52 A     L      \n 7     51 A     L      \n 8     26 A     L      \n 9     67 A     L      \n10     18 A     M      \n# … with 44 more rows\n\n\n\nwarpbreaks |> as_tibble() |> \n  pivot_wider(names_from = wool,\n              values_from = breaks,\n              values_fn = mean)\n\n# A tibble: 3 × 3\n  tension     A     B\n  <fct>   <dbl> <dbl>\n1 L        44.6  28.2\n2 M        24    28.8\n3 H        24.6  18.8"
  },
  {
    "objectID": "part04.html#不都合なデータ構造",
    "href": "part04.html#不都合なデータ構造",
    "title": "データの操作",
    "section": "不都合なデータ構造",
    "text": "不都合なデータ構造\n\nfname = \"photosynthesis1_low.csv\"\ndset1_low = read_csv(fname)\n\n\ndset1_low\n\n# A tibble: 35 × 12\n   sample   min   `0`   `5`  `10`  `15`  `20`  `25`  `30`  `35`  `40`  `45`\n    <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>\n 1      1     0  9.99 10.1  10.0  10.0  10.1   9.81 10.0  10.1  10.0  10.2 \n 2      2     0  9.97  9.99 10.1  10.0   9.99  9.94  9.91  9.95  9.79  9.97\n 3      3     0 10.0  10.1  10.1   9.97 10.1  10.0  10.0  10.0   9.88 10.0 \n 4      4     0 10.0   9.87 10.1   9.87 10.0   9.95 10.2  10.0  10.1  10.1 \n 5      5     0  9.92  9.97  9.88  9.86 10.0   9.91 10.0   9.94 10.0   9.95\n 6      1     5  9.67 10.0   9.93 10.5  10.4  10.7  10.8  10.6  10.7  10.6 \n 7      2     5  9.40  9.87 10.1  10.0  10.4  10.6  10.7  10.6  10.6  10.7 \n 8      3     5  9.37  9.84 10.2  10.3  10.5  10.6  10.5  10.6  10.7  10.7 \n 9      4     5  9.52  9.71  9.92 10.1  10.5  10.5  10.7  10.5  10.7  10.8 \n10      5     5  9.65  9.83 10.1  10.4  10.4  10.6  10.5  10.5  10.7  10.7 \n# … with 25 more rows\n\n\nsample と min の列はサンプル番号と時間 (minutes) の変数です。 それぞれに、サンプル番号と時間の値が入っています。 0 から 45 の列には溶存酸素濃度の値が入っています。 この時の変数名は光条件ですね。"
  },
  {
    "objectID": "part04.html#ワイドからロングへ変換",
    "href": "part04.html#ワイドからロングへ変換",
    "title": "データの操作",
    "section": "ワイドからロングへ変換",
    "text": "ワイドからロングへ変換\n\ndset1_low |> \n  pivot_longer(cols = matches(\"[0-9]+\"),　names_to = \"light\",\n               names_transform  = list(light = as.numeric))\n\n# A tibble: 350 × 4\n   sample   min light value\n    <dbl> <dbl> <dbl> <dbl>\n 1      1     0     0  9.99\n 2      1     0     5 10.1 \n 3      1     0    10 10.0 \n 4      1     0    15 10.0 \n 5      1     0    20 10.1 \n 6      1     0    25  9.81\n 7      1     0    30 10.0 \n 8      1     0    35 10.1 \n 9      1     0    40 10.0 \n10      1     0    45 10.2 \n# … with 340 more rows"
  },
  {
    "objectID": "part04.html#残りのデータの読み込み",
    "href": "part04.html#残りのデータの読み込み",
    "title": "データの操作",
    "section": "残りのデータの読み込み",
    "text": "残りのデータの読み込み\n\ndset1_high = read_csv(\"photosynthesis1_high.csv\")\ndset2_low  = read_csv(\"photosynthesis2_low.csv\")\ndset2_high = read_csv(\"photosynthesis2_high.csv\")"
  },
  {
    "objectID": "part04.html#ピボットしてから結合",
    "href": "part04.html#ピボットしてから結合",
    "title": "データの操作",
    "section": "ピボットしてから結合",
    "text": "ピボットしてから結合\n\ndset1_low  = dset1_low  |> pivot_longer(cols = matches(\"[0-9]+\"), names_to = \"light\", names_transform = list(light = as.numeric))\ndset1_high = dset1_high |> pivot_longer(cols = matches(\"[0-9]+\"), names_to = \"light\", names_transform = list(light = as.numeric))\ndset2_low  = dset2_low  |> pivot_longer(cols = matches(\"[0-9]+\"), names_to = \"light\", names_transform = list(light = as.numeric))\ndset2_high = dset2_high |> pivot_longer(cols = matches(\"[0-9]+\"), names_to = \"light\", names_transform = list(light = as.numeric))\nalldata = bind_rows(dset1_low, dset2_low, dset1_high, dset2_high)\nalldata\n\n# A tibble: 910 × 4\n   sample   min light value\n    <dbl> <dbl> <dbl> <dbl>\n 1      1     0     0  9.99\n 2      1     0     5 10.1 \n 3      1     0    10 10.0 \n 4      1     0    15 10.0 \n 5      1     0    20 10.1 \n 6      1     0    25  9.81\n 7      1     0    30 10.0 \n 8      1     0    35 10.1 \n 9      1     0    40 10.0 \n10      1     0    45 10.2 \n# … with 900 more rows"
  },
  {
    "objectID": "part04.html#結合してからピボット",
    "href": "part04.html#結合してからピボット",
    "title": "データの操作",
    "section": "結合してからピボット",
    "text": "結合してからピボット\n\n\nRows: 35 Columns: 12\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (12): sample, min, 0, 5, 10, 15, 20, 25, 30, 35, 40, 45\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nRows: 35 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (5): sample, min, 50, 75, 100\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nRows: 35 Columns: 12\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (12): sample, min, 0, 5, 10, 15, 20, 25, 30, 35, 40, 45\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nRows: 35 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (5): sample, min, 50, 75, 100\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\ndset1 = full_join(dset1_low, dset1_high, by = c(\"sample\", \"min\"))\ndset2 = full_join(dset2_low, dset2_high, by = c(\"sample\", \"min\"))\nalldata = bind_rows(dset1, dset2)\nalldata = alldata |> \n  pivot_longer(cols = matches(\"[0-9]+\"), names_to = \"light\", \n               names_transform = list(light = as.numeric))"
  },
  {
    "objectID": "part05.html",
    "href": "part05.html",
    "title": "ggplot の図",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.3.6      ✔ purrr   0.3.4 \n✔ tibble  3.1.8      ✔ dplyr   1.0.10\n✔ tidyr   1.2.0      ✔ stringr 1.4.0 \n✔ readr   2.1.2      ✔ forcats 0.5.1 \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\nlibrary(lubridate)\n\n\nAttaching package: 'lubridate'\n\nThe following objects are masked from 'package:base':\n\n    date, intersect, setdiff, union\n\nlibrary(readxl)\nlibrary(ggpubr)\nlibrary(showtext)\n\nLoading required package: sysfonts\nLoading required package: showtextdb\n\nlibrary(patchwork)"
  },
  {
    "objectID": "part05.html#図の詳細設定",
    "href": "part05.html#図の詳細設定",
    "title": "ggplot の図",
    "section": "図の詳細設定",
    "text": "図の詳細設定\nshowtext パッケージを使って、システムフォントを使えるようにします。 使用可能なフォントは次のように調べます。\n\n#! eval: false\nfont_files() |> as_tibble()\n\n# A tibble: 2,823 × 6\n   path                                 file        family face  version ps_name\n   <chr>                                <chr>       <chr>  <chr> <chr>   <chr>  \n 1 /usr/share/fonts/Fira_Code           FiraCode-V… Fira … Regu… Versio… FiraCo…\n 2 /usr/share/fonts/Fira_Code/static    FiraCode-B… Fira … Bold  Versio… FiraCo…\n 3 /usr/share/fonts/Fira_Code/static    FiraCode-L… Fira … Regu… Versio… FiraCo…\n 4 /usr/share/fonts/Fira_Code/static    FiraCode-M… Fira … Regu… Versio… FiraCo…\n 5 /usr/share/fonts/Fira_Code/static    FiraCode-R… Fira … Regu… Versio… FiraCo…\n 6 /usr/share/fonts/Fira_Code/static    FiraCode-S… Fira … Regu… Versio… FiraCo…\n 7 /usr/share/fonts/Fira_Mono           FiraMono-B… Fira … Bold  Versio… FiraMo…\n 8 /usr/share/fonts/Fira_Mono           FiraMono-M… Fira … Regu… Versio… FiraMo…\n 9 /usr/share/fonts/Fira_Mono           FiraMono-R… Fira … Regu… Versio… FiraMo…\n10 /usr/share/fonts/Fira_Sans_Condensed FiraSansCo… Fira … Regu… Versio… FiraSa…\n# … with 2,813 more rows\n\n\nGoogle の Noto シリーズのフォントを使いたいので、filter() にかけます。\n\nfont_files() |> as_tibble() |> \n  filter(str_detect(ps_name, \"NotoSansCJK|NotoSansSymbol\")) |> \n  select(file, face, ps_name) \n\n# A tibble: 27 × 3\n   file                          face    ps_name                  \n   <chr>                         <chr>   <chr>                    \n 1 NotoSansCJKjp-Black.otf       Regular NotoSansCJKjp-Black      \n 2 NotoSansCJKjp-Bold.otf        Regular NotoSansCJKjp-Bold       \n 3 NotoSansCJKjp-DemiLight.otf   Regular NotoSansCJKjp-DemiLight  \n 4 NotoSansCJKjp-Light.otf       Regular NotoSansCJKjp-Light      \n 5 NotoSansCJKjp-Medium.otf      Regular NotoSansCJKjp-Medium     \n 6 NotoSansCJKjp-Regular.otf     Regular NotoSansCJKjp-Regular    \n 7 NotoSansCJKjp-Thin.otf        Regular NotoSansCJKjp-Thin       \n 8 NotoSansSymbols-Black.ttf     Regular NotoSansSymbols-Black    \n 9 NotoSansSymbols-Bold.ttf      Bold    NotoSansSymbols-Bold     \n10 NotoSansSymbols-ExtraBold.ttf Regular NotoSansSymbols-ExtraBold\n# … with 17 more rows\n\n\nフォントファイルのファイル名は file 変数にあります。 その変数を使って、font_add() 関数で用意します。\n\nfont_add(family = \"notosans\", \n         regular = \"NotoSansCJKjp-Regular.otf\",\n         bold = \"NotoSansCJKjp-Black.otf\",\n         symbol = \"NotoSansSymbols-Regular.ttf\")\n\n図のデフォルトテーマをここで設定します。 base_size はフォントの大きさ。 base_family は font_add() で定義した family です。\n\ntheme_gray(base_size = 10, base_family = \"notosans\") |> theme_set()\nshowtext_auto()\n\n論文用のテーマは ggpubr パッケージの theme_pubr() をおすすめします。\n\ntheme_pubr(base_size = 10, base_family = \"notosans\") |> theme_set()\nshowtext_auto()"
  },
  {
    "objectID": "part05.html#ggplot2-について",
    "href": "part05.html#ggplot2-について",
    "title": "ggplot の図",
    "section": "ggplot2 について",
    "text": "ggplot2 について\n\nggplot2 の関数は + でつなげる\nggplot() はベースレイヤー\ngeom_*() はプロットレイヤー\nscales_*() でエステティク (aesthetics) を調整\ntheme() や theme_() で書式を調整\nfacet_wrap() や facet_grid() は多変量データのプロットのパネル分け"
  },
  {
    "objectID": "part05.html#aesthetics-エステティクとは",
    "href": "part05.html#aesthetics-エステティクとは",
    "title": "ggplot の図",
    "section": "Aesthetics （エステティク）とは",
    "text": "Aesthetics （エステティク）とは\n\n色・透明度\n\ncolor：点と線の色\nfill：面の色\nalpha：透明度（0 – 1 の値）\n\n\n\n大きさ・形状\n\nsize：点と文字の大きさ、線の太さ\nshape：点の形\nlinetype：線の種類\n\n\n\nグループ化\n\ngroup：点や線のグループ化\n\n\n\n座標、始点・終点\n\nx, y\nxmin, ymin\nxend, yend"
  },
  {
    "objectID": "part05.html#geom-の種類",
    "href": "part05.html#geom-の種類",
    "title": "ggplot の図",
    "section": "geom の種類",
    "text": "geom の種類\n散布図\n\ngeom_point()\ngeom_jitter()\n\n折れ線グラフ\n\ngeom_path()\ngeom_line()\ngeom_step()\n\n面グラフ * geom_ribbon() * geom_area() * geom_polygon()\nヒートマップ・コンター図 * geom_tile() * geom_raster() * geom_rect() * geom_contour()\nエラーバー * geom_error() * geom_linerange() * geom_pointrange() * geom_crossbar()"
  },
  {
    "objectID": "part05.html#geom-の種類-1",
    "href": "part05.html#geom-の種類-1",
    "title": "ggplot の図",
    "section": "geom の種類",
    "text": "geom の種類\n曲線など\n\ngeom_smooth()\ngeom_curve()\ngeom_segment()\ngeom_abline()\ngeom_hline()\ngeom_vline()\n\n文字列\n\ngeom_text()\ngeom_label()\n\nヒストグラム・密度曲線 * geom_histogram() * geom_freqpoly() * geom_density() * geom_bin2d() * geom_hex() * geom_dotplot()\n棒グラフ・箱ひげ図 * geom_bar() * geom_col() * geom_boxplot() * geom_violin()"
  },
  {
    "objectID": "part05.html#ggplot2-の付属パッケージ",
    "href": "part05.html#ggplot2-の付属パッケージ",
    "title": "ggplot の図",
    "section": "ggplot2 の付属パッケージ",
    "text": "ggplot2 の付属パッケージ\n研究室が使っているパッケージ\n\nggpubr: theme_pubr(), ggarrange()\nggrepel: geom_text_repel()\nlemon: facet_rep_grid(), facet_rep_wrap()\nshowtext: システムフォントの埋め込み\n\nggplot2 extensions"
  },
  {
    "objectID": "part05.html#データを読み込んだら可視化しよう",
    "href": "part05.html#データを読み込んだら可視化しよう",
    "title": "ggplot の図",
    "section": "データを読み込んだら、可視化しよう",
    "text": "データを読み込んだら、可視化しよう\n\nfilename = \"Table 2.xlsx\"\ncol_names = c(\"month\", \"temperature1\", \"sd1\", \"empty\",\"temperature2\", \"sd2\")\nexceldata = read_excel(filename, sheet = 1, skip = 2, col_name = col_names)\n\n\n\n\n\nggplot(exceldata) + geom_point(aes(x = month, y = temperature1))\n\n\n\n\n横軸の順序がおかしいですね。軸タイトルも変えたほうがいいですね。"
  },
  {
    "objectID": "part05.html#軸タイトルの関数",
    "href": "part05.html#軸タイトルの関数",
    "title": "ggplot の図",
    "section": "軸タイトルの関数",
    "text": "軸タイトルの関数\n軸タイトルや図のタイトルは labs() 関数でします。\n\nxlabel = \"Month\"\nylabel = \"'Temperature ('*degree*'C)'\" # plotmath expression see ?plotmath\nggplot(exceldata) + \n  geom_point(aes(x = month, y = temperature1)) + \n  labs(x = xlabel, \n       y = parse(text = ylabel),\n       title = \"Monthly mean water temperature\")"
  },
  {
    "objectID": "part05.html#論文用に変える",
    "href": "part05.html#論文用に変える",
    "title": "ggplot の図",
    "section": "論文用に変える",
    "text": "論文用に変える\n学術論文に記載する図の場合、図から余計なかざりを外します。 研究室では ggpubr の theme_pubr() 関数を使っています。\n\nxlabel = \"Month\"\nylabel = \"'Temperature ('*degree*'C)'\" # plotmath expression see ?plotmath\nggplot(exceldata) + \n  geom_point(aes(x = month, y = temperature1)) + \n  labs(x = parse(text = xlabel), \n       y = parse(text = ylabel))  +\n  theme_pubr(base_size = 10)"
  },
  {
    "objectID": "part05.html#月の順序をなおす",
    "href": "part05.html#月の順序をなおす",
    "title": "ggplot の図",
    "section": "月の順序をなおす",
    "text": "月の順序をなおす\nもう気づいたと思いますが、横軸の月の順序が間違っています。 factor() で、month 変数を整えます。\n\n# element_text() size is in points (pt)\n# 1 pt = 0.35 mm\nxlabel = \"Month\"\nylabel = \"'Temperature ('*degree*'C)'\" # plotmath expression see ?plotmath\n\nlevels = month.abb\nlevels = str_c(levels, ifelse(levels == \"May\", \"\", \".\"))\n\nexceldata |> \n  mutate(month = factor(month, levels = levels)) |> \n  ggplot() + \n  geom_point(aes(x = month, y = temperature1)) + \n  labs(x = parse(text = xlabel), \n       y = parse(text = ylabel))  +\n  theme_pubr(base_family = \"notosans\") +\n  theme(text = element_text(size = 10))\n\n\n\n\n\n\nLinking to ImageMagick 6.9.11.60\nEnabled features: fontconfig, freetype, fftw, heic, lcms, pango, webp, x11\nDisabled features: cairo, ghostscript, raw, rsvg\n\n\nUsing 32 threads"
  },
  {
    "objectID": "part05.html#図を保存する",
    "href": "part05.html#図を保存する",
    "title": "ggplot の図",
    "section": "図を保存する",
    "text": "図を保存する\n図は PDF と PNG 形式で保存しましょう。\nPDFファイル ggsave() は最後の表示した図を書き出しします。 width と height を指定したら必ず単位も指定しましょう (units = \"mm\")。 PDFファイルにシステムフォントを埋め込むなら、device = cairo_pdfも渡しましょう。\n\nwh = list(width = 80, height = 80) # 図の縦横幅\npdffile = \"temperature_plot.pdf\"\nggsave(pdffile, width = wh$width, height = wh$height, units = \"mm\", device = cairo_pdf)\n\nPNGファイル 直接PNGファイルに保存する場合は、画像の解像度 (dpi = 300) も必要です。\n\npngfile = \"temperature_plot.png\"\nggsave(pngfile, width = wh$width, height = wh$height, units = \"mm\", dpi = 300)"
  },
  {
    "objectID": "part05.html#保存の結果",
    "href": "part05.html#保存の結果",
    "title": "ggplot の図",
    "section": "保存の結果",
    "text": "保存の結果\n\n\n\n\n\n\nwh = list(width = 80, height = 80) は同じだが、図は似ていません。\nモニターでみたとき、PDF の解像度は 96 です。つまり、dpi = 300 のPNGファイルはPDFの約 3 倍の大きさです。"
  },
  {
    "objectID": "part05.html#図のフォントを拡大してpngファイルを修正する",
    "href": "part05.html#図のフォントを拡大してpngファイルを修正する",
    "title": "ggplot の図",
    "section": "図のフォントを拡大して、PNGファイルを修正する",
    "text": "図のフォントを拡大して、PNGファイルを修正する\n\nDPI = 300\nscale = DPI / 96\nexceldata |> \n  mutate(month = factor(month, levels = levels)) |> \n  ggplot() + \n  geom_point(aes(x = month, y = temperature1)) + \n  labs(x = parse(text = xlabel), \n       y = parse(text = ylabel))  +\n  theme_pubr(base_family = \"notosans\") +\n  theme(text = element_text(size = 10 * scale))\n\npngfile = \"temperature_plot.png\"\nwh = list(width = 80, height = 80)\nggsave(pngfile, width = wh$width, height = wh$height, units = \"mm\", dpi = DPI)"
  },
  {
    "objectID": "part05.html#研究室のワークフロー",
    "href": "part05.html#研究室のワークフロー",
    "title": "ggplot の図",
    "section": "研究室のワークフロー",
    "text": "研究室のワークフロー\nPNGファイルのDPIをいじるのが面倒なので、PDFをPNGに変換するのが楽です。 月の頭文字をチックラベルにします。さらに、lemon パッケージの geom_pointline()を使ってみました。\n\nlibrary(lemon)\n\n\nAttaching package: 'lemon'\n\n\nThe following object is masked from 'package:purrr':\n\n    %||%\n\n\nThe following objects are masked from 'package:ggplot2':\n\n    CoordCartesian, element_render\n\nxlabel = \"Month\"\nylabel = \"'Temperature'~(degree*C)\" # plotmath expression see ?plotmath\nlevels = month.abb\nlevels = str_c(levels, ifelse(levels == \"May\", \"\", \".\"))\nlabels = str_sub(month.abb, 1, 1)\n# 図の結果は plot1 にいれます。\nplot1 =   exceldata |> mutate(month = factor(month, levels = levels)) |> \n  ggplot() + \n  geom_point(aes(x = month, y = temperature1)) +\n  scale_x_discrete(name = xlabel, labels = labels) +\n  scale_y_continuous(name = parse(text = ylabel), breaks = seq(21, 29, by = 1)) +\n  theme_pubr(base_family = \"notosans\") +\n  theme(text = element_text(size = 10))\n\nまず、PDFファイルを保存します。システムフォントをPDFファイルに入れるためには device = cairo_pdf を渡します。\n\n\n\n\nwh = list(width = 80, height = 80) # 図の縦横幅\npdffile = \"temperature_plot.pdf\"\nggsave(pdffile, width = wh$width, height = wh$height, units = \"mm\", device = cairo_pdf)\n\nImageMagick のAPIを使って、PDFをPNGに変換します。 この方法だと、DPIのややこしい変換は不要です。\nつぎに magick パッケージを読み込みます。\n\nlibrary(magick) # imagemagick パッケージ\n\nつづいて、PDF ファイルを 600 DPI で読み込む。\n\nimg = image_read_pdf(pdffile, density = 600)\n\nPDFファイルをPNGファイルに書き出す。\n\nimg |> image_write(pngfile)"
  },
  {
    "objectID": "part05.html#保存の結果-1",
    "href": "part05.html#保存の結果-1",
    "title": "ggplot の図",
    "section": "保存の結果",
    "text": "保存の結果\n\n\n\n\n\nこのとき、フォントサイズは 10 pt にしました：theme(text = element_text(size = 10))。"
  },
  {
    "objectID": "part05.html#データを追加してプロット",
    "href": "part05.html#データを追加してプロット",
    "title": "ggplot の図",
    "section": "データを追加してプロット",
    "text": "データを追加してプロット\n\nxlabel = \"Month\"\nylabel = \"'Temperature'~(degree*C)\" # plotmath expression see ?plotmath\nlevels = month.abb\nlevels = str_c(levels, ifelse(levels == \"May\", \"\", \".\"))\nlabels = str_sub(month.abb, 1, 1)\nexceldata |> mutate(month = factor(month, levels = levels)) |> \n  ggplot() + \n  geom_pointline(aes(x = month, y = temperature1, color = \"Group 1\", shape = \"Group 1\", group = 1)) +\n  geom_pointline(aes(x = month, y = temperature2, color = \"Group 2\", shape = \"Group 2\", group = 1)) +\n  scale_x_discrete(name = xlabel, labels = labels) +\n  scale_y_continuous(name = parse(text = ylabel), breaks = seq(15, 30, by = 5), limits = c(15, 30)) +\n  scale_color_viridis_d(\"\", option = \"turbo\", begin = 0, end = 0.5) +\n  scale_shape_discrete(\"\") +\n  theme_pubr(base_family = \"notosans\") +\n  theme(text = element_text(size = 10),\n        legend.position = c(1, 0),\n        legend.justification = c(1, 0),\n        legend.background = element_blank(),\n        legend.title = element_blank())\n\n\n\n\n]"
  },
  {
    "objectID": "part05.html#複数パネルのプロット",
    "href": "part05.html#複数パネルのプロット",
    "title": "ggplot の図",
    "section": "複数パネルのプロット",
    "text": "複数パネルのプロット\n\nxlabel = \"Petal width (cm)\"\nylabel = \"Sepal width (cm)\"\niris |> group_nest(Species) |> \n  mutate(L = c(\"A\", \"B\", \"C\")) |> \n  mutate(Species = sprintf(\"italic('I.')~italic('%s')~'(%s)'\",  Species, L)) |> \n  unnest(data) |> \n  ggplot() + \n  geom_point(aes(x = Petal.Width, y = Sepal.Width, color = Species)) +\n  geom_text(aes(x = 3, y = 5, label = Species), parse = TRUE, vjust = 1, hjust = 1,\n            family = \"notosans\", size =3,  check_overlap = TRUE) +\n  scale_x_continuous(name = xlabel, breaks = seq(0, 3), limits = c(0, 3)) +\n  scale_y_continuous(name = ylabel, breaks = seq(0, 5), limits = c(0, 5)) +\n  scale_color_viridis_d(\"\", option = \"turbo\", \n                      begin = 0, end = 0.5, labels = scales::parse_format()) +\n  guides(color = \"none\") +\n  facet_rep_grid(cols = vars(Species)) +\n  theme_pubr(base_family = \"notosans\") +\n  theme(text = element_text(size = 10),\n        strip.background = element_blank(),\n        strip.text = element_blank())"
  },
  {
    "objectID": "part05.html#複数プロットの結合",
    "href": "part05.html#複数プロットの結合",
    "title": "ggplot の図",
    "section": "複数プロットの結合",
    "text": "複数プロットの結合\n\nxlabel1 = \"Petal width (cm)\"\nylabel1 = \"Sepal width (cm)\"\nxlabel2 = \"Petal length (cm)\"\nylabel2 = \"Sepal length (cm)\"\n\niris2 = iris |> \n    mutate(Species = sprintf(\"italic('I.')~italic('%s')\",  Species))\n\n\nplot1 = \n  ggplot(iris2) + \n  geom_point(aes(x = Petal.Width, y = Sepal.Width, color = Species)) +\n  scale_x_continuous(name = xlabel1, breaks = seq(0, 8), limits = c(0, 8)) +\n  scale_y_continuous(name = ylabel1, breaks = seq(0, 8), limits = c(0, 8)) +\n  scale_color_viridis_d(\"\", option = \"turbo\", \n                      begin = 0, end = 0.5, labels = scales::parse_format()) +\n  theme_pubr(base_family = \"notosans\") +\n  theme(text = element_text(size = 10))\n\n\nplot2 = \n  ggplot(iris2) + \n  geom_point(aes(x = Petal.Length, y = Sepal.Length, color = Species)) +\n  scale_x_continuous(name = xlabel2, breaks = seq(0, 8), limits = c(0, 8)) +\n  scale_y_continuous(name = ylabel2, breaks = seq(0, 8), limits = c(0, 8)) +\n  scale_color_viridis_d(\"\", option = \"turbo\", \n                      begin = 0, end = 0.5, labels = scales::parse_format()) +\n  theme_pubr(base_family = \"notosans\") +\n  theme(text = element_text(size = 10))"
  },
  {
    "objectID": "part05.html#複数プロットの結合の結果",
    "href": "part05.html#複数プロットの結合の結果",
    "title": "ggplot の図",
    "section": "複数プロットの結合の結果",
    "text": "複数プロットの結合の結果\n\nplot1 + plot2 + plot_layout(ncol = 2, \n                            nrow = 1, \n                            guides = \"collect\")"
  },
  {
    "objectID": "part05.html#線と点説明変数は離散型変数の場合",
    "href": "part05.html#線と点説明変数は離散型変数の場合",
    "title": "ggplot の図",
    "section": "線と点（説明変数は離散型変数の場合）",
    "text": "線と点（説明変数は離散型変数の場合）\n\nylabel = \"Petal length (cm)\"\niris2 |> group_by(Species) |> \n  summarise(PL = mean(Petal.Length),\n            sd = sd(Petal.Length)) |> \n  mutate(lower = PL - sd,\n         upper = PL + sd) |> \nggplot() + \n  geom_line(aes(x = Species, y = PL, group = 1)) +\n  geom_point(aes(x = Species, y = PL), size = 2, color = \"white\") +\n  geom_point(aes(x = Species, y = PL), size = 1) +\n  geom_errorbar(aes(x = Species, ymin = lower, ymax = upper),\n                width = 0.0) +  \n  scale_x_discrete(name = \"Species\", labels = scales::parse_format()) +\n  scale_y_continuous(name = ylabel, breaks = seq(0, 8), limits = c(0, 8)) +\n  theme_pubr(base_family = \"notosans\") +\n  theme(text = element_text(size = 10))"
  },
  {
    "objectID": "part05.html#ボーグラフ",
    "href": "part05.html#ボーグラフ",
    "title": "ggplot の図",
    "section": "ボーグラフ",
    "text": "ボーグラフ\n\nylabel = \"Petal length (cm)\"\niris2 |> group_by(Species) |> \n  summarise(PL = mean(Petal.Length),\n            sd = sd(Petal.Length)) |> \n  mutate(lower = PL - sd,\n         upper = PL + sd) |> \nggplot() + \n  geom_col(aes(x = Species, y = PL, fill = Species)) +\n  geom_errorbar(aes(x = Species, ymin = lower, ymax = upper),\n                width = 0.01) +  \n  scale_x_discrete(name = \"Species\", labels = scales::parse_format()) +\n  scale_y_continuous(name = ylabel, breaks = seq(0, 8), limits = c(0, 8)) +\n  scale_fill_viridis_d(\"\", option = \"turbo\", \n                      begin = 0, end = 0.5, labels = scales::parse_format()) +\n  guides(fill = \"none\") +\n  theme_pubr(base_family = \"notosans\") +\n  theme(text = element_text(size = 10))"
  },
  {
    "objectID": "part05.html#ボーグラフ横向き並び替える",
    "href": "part05.html#ボーグラフ横向き並び替える",
    "title": "ggplot の図",
    "section": "ボーグラフ（横向き・並び替える）",
    "text": "ボーグラフ（横向き・並び替える）\n\nylabel = \"Petal length (cm)\"\niris2 |> group_by(Species) |> \n  summarise(PL = mean(Petal.Length),\n            sd = sd(Petal.Length)) |> \n  mutate(lower = PL - sd,\n         upper = PL + sd) |> \n  ggplot(aes(x = fct_reorder(Species, PL, .desc = T))) + \n  geom_col(aes(y = PL, fill = Species)) +\n  geom_errorbar(aes(ymin = lower, ymax = upper),\n                width = 0.1) +  \n  scale_x_discrete(name = \"Species\", labels = scales::parse_format()) +\n  scale_y_continuous(name = ylabel, breaks = seq(0, 8), limits = c(0, 8)) +\n  scale_fill_viridis_d(\"\", option = \"turbo\", \n                      begin = 0, end = 0.5, labels = scales::parse_format()) +\n  guides(fill = \"none\") +\n  theme_pubr(base_family = \"notosans\") +\n  theme(text = element_text(size = 10))+ \n  coord_flip()"
  },
  {
    "objectID": "part05.html#ヒストグラム",
    "href": "part05.html#ヒストグラム",
    "title": "ggplot の図",
    "section": "ヒストグラム",
    "text": "ヒストグラム\n\nxlabel = \"Petal length (cm)\"\nylabel = \"Frequency\"\niris2 |> \n  ggplot() + \n  geom_histogram(aes(x = Petal.Length, fill = Species)) +\n  scale_x_continuous(name = xlabel) +\n  scale_y_continuous(name = ylabel) +\n  scale_fill_viridis_d(\"\", option = \"turbo\", \n                      begin = 0, end = 0.5, labels = scales::parse_format()) +\n  theme_pubr(base_family = \"notosans\") +\n  theme(text = element_text(size = 10),\n        legend.position = c(1,1),\n        legend.justification = c(1,1))\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`."
  },
  {
    "objectID": "part05.html#ヒストグラムパネル",
    "href": "part05.html#ヒストグラムパネル",
    "title": "ggplot の図",
    "section": "ヒストグラム・パネル",
    "text": "ヒストグラム・パネル\n\nxlabel = \"Petal length (cm)\"\nylabel = \"Frequency\"\niris2 |> \n  ggplot() + \n  geom_histogram(aes(x = Petal.Length, fill = Species),\n                 binwidth = 0.1, center = 0) +\n  scale_x_continuous(name = xlabel, limits = c(0, 10)) +\n  scale_y_continuous(name = ylabel) +\n  scale_fill_viridis_d(\"\", option = \"turbo\", \n                      begin = 0, end = 0.5, labels = scales::parse_format()) +\n  facet_rep_wrap(facets = vars(Species)) +\n  theme_pubr(base_family = \"notosans\") +\n  theme(text = element_text(size = 10),\n        legend.position = c(1,1),\n        legend.justification = c(1,1),\n        strip.background = element_blank(),\n        strip.text = element_blank())\n\nWarning: Removed 6 rows containing missing values (geom_bar)."
  },
  {
    "objectID": "part05.html#時系列",
    "href": "part05.html#時系列",
    "title": "ggplot の図",
    "section": "時系列",
    "text": "時系列\nデータは (https://covid.ourworldindata.org/data/owid-covid-data.csv)。\n\ncovid = read_csv(\"https://covid.ourworldindata.org/data/owid-covid-data.csv\")\n\nRows: 216106 Columns: 67\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr   (4): iso_code, continent, location, tests_units\ndbl  (62): total_cases, new_cases, new_cases_smoothed, total_deaths, new_dea...\ndate  (1): date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\ncovid2 = covid |> \n  group_by(continent, date) |> \n  summarise(tc = sum(total_cases_per_million, na.rm=T),\n            td = sum(total_deaths_per_million, na.rm= T)) |> \n  drop_na()\n\n`summarise()` has grouped output by 'continent'. You can override using the\n`.groups` argument.\n\n\n\nxlabel = \"Date\"\nylabel = \"COVID cases per million\"\nggplot(covid2) +\n  geom_path(aes(x=date, y = tc, color = continent))+\n  scale_x_date(name = xlabel) +\n  scale_y_continuous(name = ylabel) +\n  scale_color_viridis_d(\"\", option = \"turbo\", begin = 0, end = 0.8) +\n  theme_pubr(base_family = \"notosans\") +\n  theme(text = element_text(size = 10),\n        legend.position = c(0,1),\n        legend.justification = c(0,1),\n        strip.background = element_blank(),\n        strip.text = element_blank())"
  },
  {
    "objectID": "part05.html#時系列-1",
    "href": "part05.html#時系列-1",
    "title": "ggplot の図",
    "section": "時系列",
    "text": "時系列\n\nxlabel = \"Date\"\nylabel = \"COVID cases per million\"\nggplot(covid2) +\n  geom_path(aes(x=date, y = tc, color = continent))+\n  scale_x_date(name = xlabel, date_labels = \"%Y-%m-%d\") +\n  scale_y_continuous(name = ylabel, \n                     breaks = 10^seq(-2,7), limits = c(0.01, 10^7),\n                     trans = \"log10\", labels = scales::label_math(format = log10)) +\n  scale_color_viridis_d(\"\", option = \"turbo\", begin = 0, end = 0.8) +\n  guides(color = guide_legend(ncol = 2)) +\n  theme_pubr(base_family = \"notosans\") +\n  theme(text = element_text(size = 10),\n        legend.position = c(0.5,0),\n        legend.justification = c(0,0),\n        legend.background = element_blank(),\n        strip.background = element_blank(),\n        strip.text = element_blank())\n\nWarning: Transformation introduced infinite values in continuous y-axis"
  },
  {
    "objectID": "part05.html#時系列軸のカスタムラベル",
    "href": "part05.html#時系列軸のカスタムラベル",
    "title": "ggplot の図",
    "section": "時系列軸のカスタムラベル",
    "text": "時系列軸のカスタムラベル\n\ngnn_date = function() {\n  function(x) {\n    m = format(x, \"%b\")\n    m = str_sub(m, start = 1, end = 1)\n    y = format(x, \"%Y\")\n    ifelse(duplicated(y), m, sprintf(\"%s\\n%s\", m,y))\n  }\n}"
  },
  {
    "objectID": "part05.html#時系列-2",
    "href": "part05.html#時系列-2",
    "title": "ggplot の図",
    "section": "時系列",
    "text": "時系列\n\nxlabel = \"Date\"\nylabel = \"COVID cases per million\"\nggplot(covid2) +\n  geom_path(aes(x=date, y = tc, color = continent))+\n  scale_x_date(name = xlabel, date_breaks = \"months\", labels = gnn_date()) +\n  scale_y_continuous(name = ylabel, \n                     breaks = 10^seq(-2,7, by = 2), limits = c(0.01, 10^7),\n                     trans = \"log10\", labels = scales::label_math(format = log10)) +\n  scale_color_viridis_d(\"\", option = \"turbo\", begin = 0, end = 0.8) +\n  guides(color = guide_legend(ncol = 2)) +\n  theme_pubr(base_family = \"notosans\") +\n  theme(text = element_text(size = 10),\n        legend.position = c(0.5,0),\n        legend.justification = c(0,0),\n        legend.background = element_blank(),\n        strip.background = element_blank(),\n        strip.text = element_blank())\n\nWarning: Transformation introduced infinite values in continuous y-axis"
  },
  {
    "objectID": "part05.html#箱ひげ図",
    "href": "part05.html#箱ひげ図",
    "title": "ggplot の図",
    "section": "箱ひげ図",
    "text": "箱ひげ図\n\ncovid2 = covid |> \n  filter(date >= lubridate::ymd(\"2021-01-01\")) |> \n  filter(str_detect(location, \"Indonesia|Japan|South Korea|Taiwan|China\"))\n\n\nxlabel = \"Country\"\nylabel = \"Daily cases per million\"\nggplot(covid2) +\n  geom_boxplot(aes(x = fct_reorder(location, new_cases_per_million, mean, na.rm=T, .desc=T), \n                   y = new_cases_per_million, fill = location)) + \n  scale_x_discrete(name = xlabel) +\n  scale_y_continuous(name = ylabel, \n                     breaks = 10^seq(-3,3, by = 1), limits = 10^c(-3, 3),\n                     trans = \"log10\", labels = scales::label_math(format = log10)) +\n  scale_color_viridis_d(\"\", option = \"turbo\",  begin = 0, end = 0.8) +\n  guides(fill = guide_legend(ncol = 2)) +\n  theme_pubr(base_family = \"notosans\") +\n  theme(text = element_text(size = 10),\n        legend.position = c(0,0),\n        legend.justification = c(0,0),\n        legend.background = element_blank(),\n        legend.title = element_blank(),\n        strip.background = element_blank(),\n        strip.text = element_blank())\n\nWarning: Transformation introduced infinite values in continuous y-axis\n\n\nWarning: Removed 316 rows containing non-finite values (stat_boxplot)."
  },
  {
    "objectID": "summary-statistics.html#rスクリプトの準備",
    "href": "summary-statistics.html#rスクリプトの準備",
    "title": "記述統計",
    "section": "Rスクリプトの準備",
    "text": "Rスクリプトの準備\nRコードは上から下へと実行します。スクリプトの冒頭には少なくともタイトル、作者名、作成日をコメントとして入れましょう。コメントは # の後に 1 つの半角スペースを入れてから書いてください。\n\n# 記述統計量の求め方\n# Greg Nishihara\n# 2022 May 01"
  },
  {
    "objectID": "summary-statistics.html#データの準備",
    "href": "summary-statistics.html#データの準備",
    "title": "記述統計",
    "section": "データの準備",
    "text": "データの準備\n実際の解析の場合、データはエクセルやCSV（コンマ区切り）ファイルから読み込みます。クラウド（Google sheet）からの読み込みも可能です。ここでは、直接スクリプトに書き込みます。\n長崎市気象台から2022年5月1日から14日までの日ごとの平均気温は次の通りです。\n\ntemperature = c(16.3, 16.9, 17.1, 17.3, 20.0, \n                21.1, 21.4, 20.6, 19.7, 21.0, \n                20.6, 21.1, 20.0, 19.4)\n\nc() は複数値を一つのベクトル [^vector] に concatenate（連結）するために使います。c() の結果は temperature というオブジェクトに書き込みました。\n\n\n\n\n\n\nImportant\n\n\n\nRの変数名と関数名には、文字・数字・ドット・アンダースコアをつきますが、先頭の 1 文字は文字かドットじゃないといけません。\n次のような名前はOKです。\n\ntemperature     = c(16.3, 16.9)\nTemperature     = c(16.3, 16.9)\n.temperature    = c(16.3, 16.9)\ntemp.erature    = c(16.3, 16.9)\ntem_pera_ture   = c(16.3, 16.9)\ntemperature2022 = c(16.3, 16.9)"
  },
  {
    "objectID": "summary-statistics.html#平均値や標準偏差などの求め方",
    "href": "summary-statistics.html#平均値や標準偏差などの求め方",
    "title": "記述統計",
    "section": "平均値や標準偏差などの求め方",
    "text": "平均値や標準偏差などの求め方\n平均値 \\overline{x} は次のように定義できます。\n\n\\overline{x} = \\frac{1}{N}\\sum_{n = 1}^{N} x_n\n\nx_n はインデクス n の値です。値は合計 N あります。\n平均値は mean() 関数で求めます。mean() には処理したいベクトルを渡してください。\n\nmean(temperature)\n\n[1] 19.46429\n\n\n分散 s^2=Var(x) は次のように定義します。\n\ns^2 = Var(x) = \\frac{1}{N}\\sum_{n = 1}^{N} \\left(x_n-\\overline{x} \\right)^2\n\n標準偏差は分散の平方根 (s = \\sqrt{s^2}) です。\n分散と標準偏差はそれぞれ、var()と sd() で求めます。\n\nvar(temperature) # 分散\n\n[1] 3.19478\n\nsd(temperature)  # 標準偏差\n\n[1] 1.787395\n\n\n専用の標準誤差の関数はありませんが、関数を組み合わせて、求めまれます。\n標準誤差 (SE) は次の式で求めます。\n\n\\text{SE} =s / \\sqrt{N}\n\n\nsd(temperature) / sqrt(length(temperature))\n\n[1] 0.4777014\n\n\nlength() 関数はベクトルのサイズ（要素の数）を求めてくれます。その結果を sqrt() に直接渡します。標準偏差をこの結果で割れば、標準誤差が求められます。このコードを分解すると、次のようになります。\n\ns = sd(temperature) # 標準偏差\ns\n\n[1] 1.787395\n\nn = length(temperature) # データ数\nn\n\n[1] 14\n\nsqrtn = sqrt(n) # データ数の平方根\nsqrtn\n\n[1] 3.741657\n\ns / sqrtn # 標準誤差\n\n[1] 0.4777014"
  },
  {
    "objectID": "summary-statistics.html#中央値と中央絶対偏差",
    "href": "summary-statistics.html#中央値と中央絶対偏差",
    "title": "記述統計",
    "section": "中央値と中央絶対偏差",
    "text": "中央値と中央絶対偏差\n中央値 (median, \\tilde{x} ) と中央絶対偏差 (MAD, median absolute deviation) も記述統計量の一種です。中央値は次のアルゴリズムで求めます。\n\nデータを小さい順に並べる。\nデータ数が奇数のとき、中央値は (n+1)/2 番目の値です。\nデータ数が偶数のとき、中央値は n/2 と (n/2)+1 番目のデータの平均値です。\n\n\nmedian(temperature)\n\n[1] 20\n\n\nこのとき、データ数は奇数あるので、7番目の値が中央値です。\n\n\n\n\nntemperature116.3216.9317.1417.3519.4619.7720.0820.0920.61020.61121.01221.11321.11421.4\n\n\n中央絶対偏差は次のように定義します。\n\n\\text{MAD}=\\text{median}\\left(|x_n - \\tilde{x}|\\right)\n\n\nmedian(abs(temperature - median(temperature)))\n\n[1] 1.05\n\n\n\n\n\n\n\n\nNote\n\n\n\n中央絶対偏差と標準偏差はデータのばらつきの度合を説明するときに使います。標準偏差は外れ値の大きく影響されますが、中央絶対偏差は外れ値の影響にロバスト (robust)　です。"
  },
  {
    "objectID": "summary-statistics.html#外れ値の影響",
    "href": "summary-statistics.html#外れ値の影響",
    "title": "記述統計",
    "section": "外れ値の影響",
    "text": "外れ値の影響\n標準偏差と中央絶対偏差における外れ値の影響を調べてみましょう。 まずは、中央絶対偏差用の関数を定義します。\n\nmad = function(x) {\n  median(abs(x - median(x)))\n}\n\ntemperature に外れ値を追加します。\n\noutlier = 25\ntemperature_with_outlier = c(temperature, outlier)\n\n外れ値のないときの標準偏差と中央絶対偏差は次の通りです。\n\nsd(temperature)   # 標準偏差\n\n[1] 1.787395\n\nmad(temperature)  # 中央絶対偏差\n\n[1] 1.05\n\n\n\nsd(temperature_with_outlier)   # 標準偏差\n\n[1] 2.238197\n\nmad(temperature_with_outlier)  # 中央絶対偏差\n\n[1] 1.1\n\n\n外れ値が存在するときに、標準偏差の値が大きく変わりましたが、 中央絶対偏差の変化は比較的に小さいです。\n\n\n\n\n\n\nNote\n\n\n\nばらつきを示す指標は、標準偏差と中央絶対偏差以外に、平均絶対偏差 (mean absolute deviation) や四分位偏差 (quartile deviation) もあります。平均絶対偏差は次の式で求めます。 \n\\text{MAD}_\\text{mean} = \\frac{1}{N}\\sum_{n=1}^N |x_n - \\overline{x}|\n 四分位偏差は次の式で求めます。 \nIQR = \\frac{1}{2}(Q_3 - Q1)\n Q_3 は第3四分位数、Q_1 は第1四分位数を示します。\n\nmad2 = function(x) {\n  mean(abs(x - mean(x)))\n}\niqrdev = function(x) {\n  as.numeric(diff(quantile(x, probs = c(0.25, 0.75))))\n}\n\nmad2(temperature_with_outlier)   # 平均絶対偏差\n\n[1] 1.64\n\niqrdev(temperature_with_outlier) # 四分位偏差\n\n[1] 2.7"
  },
  {
    "objectID": "summary-statistics.html#偏差の結果",
    "href": "summary-statistics.html#偏差の結果",
    "title": "記述統計",
    "section": "偏差の結果",
    "text": "偏差の結果\n\n\n\n\n外れ値標準偏差中央絶対偏差平均絶対偏差四分位偏差あり2.2381971.101.640002.700なし1.7873951.051.474493.075"
  },
  {
    "objectID": "ttest.html",
    "href": "ttest.html",
    "title": "2群の比較：t 検定",
    "section": "",
    "text": "ノコギリモク (Sargassum macrocarpum) は褐藻類ホンダワラ属の海藻です。 通年藻場を形成する海藻であり、海洋動物の住処、餌場、炭素固定の場として機能しています。 かつて、九州に広く分布していましたが、温暖化に伴う環境変動と食害によって、局地的に絶滅しています。 ここでは、ノコギリモクの幼体を資料として、2軍における解析手法を紹介します。\nでは、地点 A と B のノコギリモク幼体の幅は Table 1 の通りです。 各地点から合計６個体採取しました。"
  },
  {
    "objectID": "ttest.html#作業仮説を考えましょう",
    "href": "ttest.html#作業仮説を考えましょう",
    "title": "2群の比較：t 検定",
    "section": "作業仮説を考えましょう",
    "text": "作業仮説を考えましょう\n\n\n\n\n\n\n作業仮設1\n\n\n\nすべての研究は作業仮説 から始まります。\n今回の例について、作業仮説は 「地点毎に対するノコギリモク幼体の幅は異なる」にしました。"
  },
  {
    "objectID": "ttest.html#帰無仮説有意生検定が必要とする仮説を決めます",
    "href": "ttest.html#帰無仮説有意生検定が必要とする仮説を決めます",
    "title": "2群の比較：t 検定",
    "section": "帰無仮説有意生検定が必要とする仮説を決めます",
    "text": "帰無仮説有意生検定が必要とする仮説を決めます\n作業仮説を定義したら、つぎは検定のための仮説を定義します。 帰無仮説有意性検定 2\n\nH_0 (null hypothesis 帰無仮説): 平均値に違いはない (\\mu_{A} = \\mu_{B})\nH_A (alternative hypothesis 対立仮設): 平均値は異なる (\\mu_{A} \\neq \\mu_{B})\n\nつぎのような対立仮説も思いつきます。\n\nH_P (対立仮設): \\mu_A > \\mu_B\nH_N (対立仮設): \\mu_A < \\mu_B\n\n\n\n\n\n\n\n無限に存在する\n\n\n\n帰無仮説と対立仮説はいくらでも考えられますが、 \\mu_A = \\mu_B は一般的な帰無仮説です。 そして、\\mu_A \\neq \\mu_B も一般的な対立仮説です。"
  },
  {
    "objectID": "ttest.html#ナイーブ-な解析手法",
    "href": "ttest.html#ナイーブ-な解析手法",
    "title": "2群の比較：t 検定",
    "section": "ナイーブ 3 な解析手法",
    "text": "ナイーブ 3 な解析手法\n地点 A と B のノコギリモクの大きさの違いが知りたいです。 では、地点同士の大きさの違いを求めます。 地点 A と B の平均値の差を求めてみます。\n\n\\overline{x_A} - \\overline{x_B} = -2.22\n 地点 B のノコギリモクが大きいです。 でも、この大きさはどの程度信用できるかがわかりません。 平均値の差の制度を評価するには、標準誤差 4 を求めないといけないです。 この手法だと、標準誤差は求められません。\nでは、かく地点のサンプル番号ごとの差をとってみます。 この場合、 6 つの差を求められます。 6 つあるので、平均値、標準偏差、標準誤差も求められます。\n\n\n\n\nTable 3:  ノコギリモクの幅 (mm) とペア毎の差 \nSampleSite ASite BDifference119.922.319.90 - 22.30 = -2.40220.622.920.60 - 22.90 = -2.30320.322.020.30 - 22.00 = -1.70420.423.720.40 - 23.70 = -3.30520.920.920.90 - 20.90 = 0.00618.121.718.10 - 21.70 = -3.60\n\n\n\n\n\n\n\n\\overline{x} = -2.2\ns = 1.3\n\\text{s.e.} = 0.53\n\n問題は、この差の平均値をどのように評価するのか。"
  },
  {
    "objectID": "ttest.html#平均値の分布",
    "href": "ttest.html#平均値の分布",
    "title": "2群の比較：t 検定",
    "section": "平均値の分布",
    "text": "平均値の分布\n\n\n\n\n\n\n\nFigure 2: 求めた平均値と標準誤差から推定した正規分布。\n\n\n\n\n\n\n中心極限定理 5によると、平均値の分布は正規分布 6に従います。\nFigure 2 に示した紫色の部分は 95% の確率密度です。 その幅は 信頼区間 7といいます。 有意水準を \\alpha = 0.05 として定義したとき、 この信頼区間は 95% 信頼区間 8といいます。\n\n\n\n\n\n\n\n\n信頼区間とは？\n\n\n\n[l, u] の区間を定義したとき、l は区間の下限、u は区間の上限です。 このように定義した区間は信頼区間といいます。\nでは、x に対する区間 [l,u] は 1-\\alpha の確率で次のように定義できます。\n\nP(l \\le x \\le u) = 1-\\alpha\n\n\\overline{x} が標本平均であれば、z値 9と呼ぶ統計量を定義できます。\n\nz = \\frac{\\overline{x}-\\mu}{\\sigma}\n\n\\mu は母平均、\\sigma は母分散です。\nつまり、下限と上限を求めるためには\n\nP(l \\le z \\le u) = 1-\\alpha\n\nを解けばいい。\n中心極限定理は次の通りに定義されています。\n\n\\lim_{n\\rightarrow\\infty} \\sqrt{n}\\overbrace{\\left(\\frac{\\overline{x}_n-\\mu}{\\sigma}\\right)}^\\text{この部分は z 値}  \\xrightarrow{d} N(0, 1)\n\nよって、 \\alpha = 0.05　のときの [l, u] は次の通りです。\n\nP\\left(l \\le z \\le u \\right) = 1-0.05 = 0.95\n\n標準化正規分布 N(0,1) のとき、\n\n\\alpha/2=0.05/2=0.025 分位数は l です。\n1-\\alpha/2=1-0.05/2=0.975 分位数は u です。"
  },
  {
    "objectID": "ttest.html#z-値の分位数を求める",
    "href": "ttest.html#z-値の分位数を求める",
    "title": "2群の比較：t 検定",
    "section": "z 値の分位数を求める",
    "text": "z 値の分位数を求める\n\n\n\n\n\nFigure 3: 標準化正規分布\n\n\n\n\n\n[-1 s, 1 s] は 68.3% 区間\n[-2 s, 2 s] は 95.4% 区間\n[-3 s, 3 s] は 99.7% 区間\n\n\n\n\n\n\n\n\nTable 4:  標準化正規分布の分位数 \nSignififance levelpercent± quantile0.5000000000050.000000.67448980.3173105078668.268951.00000000.2000000000080.000001.28155160.1000000000090.000001.64485360.0500000000095.000001.95996400.0455002639095.449972.00000000.0250000000097.500002.24140270.0026997960699.730023.00000000.0000633424899.993674.0000000"
  },
  {
    "objectID": "ttest.html#信頼区間の求め方",
    "href": "ttest.html#信頼区間の求め方",
    "title": "2群の比較：t 検定",
    "section": "信頼区間の求め方",
    "text": "信頼区間の求め方\n平均値は \\overline{x}_{A-B} = 21.142 です。 標準誤差は \\text{s.e.} = 0.431 です。 母分散は \\sigma_A = \\sigma_B = 1 です。 有意水準は \\alpha = 0.05 とします。\n95% 信頼区間は次のように定義しています。 \nP\\left(l \\le \\frac{\\overline{x}-\\mu}{\\sigma}\\le u\\right) = 1-\\alpha = 0.95\n\n書き直すと次のとおりです。\n\nP\\left(\\overline{x} +l \\sigma \\le \\mu \\le \\overline{x} + u\\sigma\\right) = 1-\\alpha = 0.95\n\n\\alpha= 0.05　のとき、 l= -1.96 と u= 1.96 です。\n母分散は先程定義しましたが、\\sigma = 1 です。 それぞれの値を式に代入すると、次のとおりです。\n\n\\begin{split}\nP(\n21.142 +  -1.96 \\times 1\n\\le x \\le\n21.142 +  1.96 \\times 1\n) &=\nP(\n\\overbrace{19.182}^{l}\n\\le x \\le\n\\overbrace{23.102}^{u}\n) \\\\\n&= 0.95\n\\end{split}\n\nつまり、 \\overline{x}= 21.142 の 95% 信頼区間は [19.182, 23.102 ] です。\n\n\n\n\n\nFigure 4: 調査を 20 回行ったときの平均値と信頼区間。真の平均値は -2 です。このとき、全ての実験で求めた信頼区間内に真の平均値が存在します。\n\n\n\n\n信頼区間内に 0 が含まれるときの、帰無仮説は棄却できません。 ちなみに、このときの帰無仮説は「平均値はゼロ」です。\n\n\n\n\n\nFigure 5: ゼロを含む信頼区間。\n\n\n\n\n\n真の平均値は -2 なので、仮定した帰無仮説はそもそも誤りです。\nH_0 を棄却しなかったら、 第2種の誤り 10がおきます。\n8 つの調査の 95% 信頼区間は 0 を含みます。つまり、第2種の誤りは \\beta= 8 / 20 = 0.4 (40%) です。\nこの解析の検出力 (1 - \\beta) は 0.6 です。正しい結果に導く確率は 60% です。"
  },
  {
    "objectID": "ttest.html#解析は誤りです",
    "href": "ttest.html#解析は誤りです",
    "title": "2群の比較：t 検定",
    "section": "解析は誤りです!",
    "text": "解析は誤りです!\nz 値は正規分布に従いますが、このとき母平均と母分散は存知です。\n\nz = \\frac{\\overline{x} - \\mu}{\\sigma}\\sim N(0,1)\n\n++ところが、一般的には母平均と母分散は未知です。** 一般的には z 値より、t 値を求めます。\n\nt_{\\overline{x}} = \\frac{\\overline{x} - x_0}{s.e.} = \\frac{\\overline{x} - x_0}{s / \\sqrt{n}}\n\nt 値は t 分布に従います。\n\n\n\n\n\nFigure 6: ｔ分布\n\n\n\n\nこの t 分布の 自由度 11は N-1 = 5 です。\n\n\n\n\nTable 5:  自由度 5 のときに t 分布の分位数 \nSignififance levelpercent± quantile0.5000000050.000000.72668680.3632174763.678251.00000000.2000000080.000001.47588400.1019394889.806052.00000000.1000000090.000002.01504840.0500000095.000002.57058180.0300992596.990083.00000000.0250000097.500003.16338140.0103234298.967664.0000000\n\n\n\n\n\n\n\n\nFigure 7: 母分散が未知のときの結果\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nFigure 7 は 20 の標本平均とそれぞれの 95% 信頼区間を示しています。 真の平均値が頼区間に含まれている実験は紫色で示しています。 20 の調査のうち、新の平均値を含む回数は 19 回です。\n信頼区間の解釈について\n基本的には、95%　信頼区間を次のように理解できる。 実験を 100 回行い、信頼区間内に真の平均値が含まれる回数は 95 回です。。\n下記で述べた解釈はすべて誤りです。\n\n信頼区間に真の平均値が存在する。\n95% の確率で真の平均値が信頼区間に含まれる。\n95% の確率で次の実験の平均値が信頼区間に含まれる。\n\n\n\n\n\n\n\n\nFigure 8: 信頼区間にゼロが含まれる回数\n\n\n\n\n\n信頼区間に 0 を含む実験は 5つあるので、 \\beta= 5 / 20 = 0.25 (25%) です。\nこの実験の検出力 (1 - \\beta) は 0.75　です。"
  },
  {
    "objectID": "ttest.html#対応ありの-t-検定",
    "href": "ttest.html#対応ありの-t-検定",
    "title": "2群の比較：t 検定",
    "section": "対応ありの t 検定",
    "text": "対応ありの t 検定\n\n\n\n\n\nFigure 9: 対応ありの t 検定\n\n\n\n\nこのときの第２種の誤りををこす確率は \\beta = 5 / 20 = 25% です。 検出力　(1-\\beta) は 0.75です。"
  },
  {
    "objectID": "ttest.html#分散が異なる-t-検定",
    "href": "ttest.html#分散が異なる-t-検定",
    "title": "2群の比較：t 検定",
    "section": "分散が異なる t 検定",
    "text": "分散が異なる t 検定\n\n\n\n\n\nFigure 10: 分散が異なる t 検定（ウェルチの t 検定ともよびます）\n\n\n\n\nこのときの第２種の誤りををこす確率は \\beta = 1 / 20 = 5% です。\n検出力 (1-\\beta) はs 0.95 です。"
  },
  {
    "objectID": "ttest.html#対応ありの-t-検定-1",
    "href": "ttest.html#対応ありの-t-検定-1",
    "title": "2群の比較：t 検定",
    "section": "対応ありの t 検定",
    "text": "対応ありの t 検定\n対応ありのt検定 (paired t-test)\nt 検定の統計量は t 値です。\n\nt^* = \\frac{\\overline{x}_{A-B} - \\mu}{s_{A-B} / \\sqrt{n}}\n\n対応ありの t 検定の自由度は n-1　です。\n観測値がペアとして対応しているときに使います。 たとえば、低い光環境で育て海藻を高い光環境に移した時の成長速度の差を比較するときに使います。"
  },
  {
    "objectID": "ttest.html#標本の-t-検定",
    "href": "ttest.html#標本の-t-検定",
    "title": "2群の比較：t 検定",
    "section": "2標本の t 検定",
    "text": "2標本の t 検定\n2標本 （２群）t 検定には 2 種類あります。\n等分散の t 検定 (equal variance t-test)\n\nt^* = \\frac{\\overline{x}_A - \\overline{x}_B}{s_p \\sqrt{1 / n_A + 1/n_B}}\n \ns_p = \\sqrt{\n\\frac{(n_A-1)s_A^2 + (n_B-1)s_B^2}\n{n_A + n_B -2}}\n 自由度は n_A + n_B - 2　です。\n不等分散の t 検定・ウェルチの t 検定 (Unequal variance, Welch’s t-test)\n\nt^* = \\frac{\\overline{x}_A - \\overline{x}_B}{s_p}\n\n\ns_p = \\sqrt{\n\\frac{s_A^2}{n_A} +\n\\frac{s_B^2}{n_B}}\n 自由度はウェルチ–サタスウェイトの式 (Welch-Satterthwaite Equation) で求めます。\ns は標準偏差、 n サンプル数、 \\overline{x} は平均値、 t^* は t 値。\n\n\\text{degrees-of-freedom} =\n\\frac{\n\\left(\\frac{s_A^2}{n_A} + \\frac{s_B^2}{n_B}\\right)^2\n}\n{\\frac{\\left(s_A^2 / n_A\\right)^2}{n_A-1} + \\frac{\\left(s_B^2 / n_B\\right)^2}{n_B-1}}\n\ndegrees-of-freedom は自由度です。"
  },
  {
    "objectID": "ttest.html#ノコギリモク幼体の幅に対する-t-検定",
    "href": "ttest.html#ノコギリモク幼体の幅に対する-t-検定",
    "title": "2群の比較：t 検定",
    "section": "ノコギリモク幼体の幅に対する t 検定",
    "text": "ノコギリモク幼体の幅に対する t 検定\n\n\n対応ありの t 検定\n\n\n\n\n\\begin{aligned}\nt^* &= \\frac{\\overline{x}_{A-B} - \\mu}{s_{A-B} / \\sqrt{n}} \\\\\nt^* &= \\frac{-2.467}{2.642 / \\sqrt{6}} \\\\\nt^* &= -2.287\n\\end{aligned}\n\n\n\n\n\\overline{x}_{A-B}= -2.467\ns_{A-B}= 2.642\n\\mu=0\nn = 6\n\\alpha = 0.05\nt値: -2.287\nP値: 0.071\n\n\n\nノコギリモク幼体のデータはお互いに対応していないので、対応ありの t 検定の結果は誤りです。\n\n\nノコギリモク幼体の正しい解析はウェルチの t 検定です。\n\n\\begin{aligned}\nt^* &= \\frac{\\overline{x}_A -\\overline{x}_B}{s_p} \\\\\ns_p &= \\sqrt{\\frac{s_A^2}{n_A} + \\frac{s_B^2}{n_B}} \\\\\ns_p &= \\sqrt{\\frac{1.995^2}{6} + \\frac{1.961^2}{6}} \\\\\nt^* &= \\frac{10.05 - 12.517}{1.142} \\\\\nt^* &= -2.16 \\\\\n\\text{d.f.} &= 9.997\n\\end{aligned}\n\n\n\n\n\\alpha = 0.05\nt値-value: -2.16\nP値: 0.056\n\nP\\nless \\alpha = 0.05 なので、帰無仮説は棄却できません。"
  },
  {
    "objectID": "ttest.html#サンプル数と-p-値の関係",
    "href": "ttest.html#サンプル数と-p-値の関係",
    "title": "2群の比較：t 検定",
    "section": "サンプル数と p 値の関係",
    "text": "サンプル数と p 値の関係\n\n\n\n\n\n分散等しい t 検定の場合、サンプル数が増えると第 2 種の誤りは減少し、検出力は増加します。第 1 種の誤りは変わりません。\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nsite A の真の平均値は \\mu = 20、site B のは \\mu = 22 です。 site A の真の平均値は \\mu = 20、site B のは \\mu = 22 です。 site A と site B の真の標準偏差 (\\sigma) は 1 と 1 です。"
  },
  {
    "objectID": "ttest.html#behavior-of-the-t-test-unequal-variance",
    "href": "ttest.html#behavior-of-the-t-test-unequal-variance",
    "title": "2群の比較：t 検定",
    "section": "Behavior of the t-test (unequal variance)",
    "text": "Behavior of the t-test (unequal variance)\n\n\n\n\n\n分散が異なる t 検定の場合、第 2 種の誤りと検出力の動きは分散が等しい t 検定と似ていますが、標本数も強く影響します。\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nsite A の真の平均値は \\mu = 20、site B のは \\mu = 22 です。 site A の真の標準偏差は \\mu = 1、ですが、site B の標準偏差は \\sigma_B = k\\times\\sigma_A です。 s_A / s_B \\rightarrow\\inftyのとき、第2種の誤りは増加し、検出力は減少します。 さらに、標本数が増えると、不等分散性の影響が下がります。"
  },
  {
    "objectID": "ttest.html#ウェルチ-t-検定の-r-出力と結果",
    "href": "ttest.html#ウェルチ-t-検定の-r-出力と結果",
    "title": "2群の比較：t 検定",
    "section": "ウェルチ t 検定の R 出力と結果",
    "text": "ウェルチ t 検定の R 出力と結果\n\n\n\n    Welch Two Sample t-test\n\ndata:  value by name\nt = -2.16, df = 9.9971, p-value = 0.05612\nalternative hypothesis: true difference in means between group A and group B is not equal to 0\n95 percent confidence interval:\n -5.01124979  0.07791646\nsample estimates:\nmean in group A mean in group B \n       10.05000        12.51667 \n\n\n\n# パッケージの読み込み\nlibrary(tidyverse)\n\n# 疑似データの作成\nA = c(9.8,11.1,10.7,10.7,11.8,6.2)\nB = c(12.5,13.8,12.0,15.5,9.8,11.5)\ndata = tibble(A, B)\ndata = data %>% pivot_longer(cols = c(A,B))\n\n# ウェルチ t 検定\nt.test(value ~ name, data = data)\n\n\n# ひと書き方\nt.test(A, B)\n\n\n# two-sample, equal variance t-test (等分散 t 検定)\nt.test(value ~ name, data = data, var.equal = TRUE)"
  },
  {
    "objectID": "ttest.html#パッケージの読み込み",
    "href": "ttest.html#パッケージの読み込み",
    "title": "2群の比較：t 検定",
    "section": "パッケージの読み込み",
    "text": "パッケージの読み込み\nt 検定だけしたいなら、次のパッケージの読み込みは不要です。 そう言っても、自分のワークフローでは、つぎのパッケージは必ず読み込んでいます。 パッケージを読み込もうとしたときに、 Error in library(tidyverse) : there is no package called 'tidyverse' のようなエラーがでたら、パッケージのインストールが必要です。\nパッケージのインストールは次のようにできます。\n\ninstall.packages(\"tidyverse\")\n\nでは、パッケージを読み込みます。\n\nlibrary(tidyverse)  # データの操作・処理・作図用メタパッケージ\nlibrary(readxl) 　　# xlsx ファイルの読み込み用\nlibrary(lubridate)　# 時刻データ用\n\n\nAttaching package: 'lubridate'\n\n\nThe following objects are masked from 'package:base':\n\n    date, intersect, setdiff, union"
  },
  {
    "objectID": "ttest.html#データの準備",
    "href": "ttest.html#データの準備",
    "title": "2群の比較：t 検定",
    "section": "データの準備",
    "text": "データの準備\nデータは CSV (Comma Separated Value; コンマ区切り) ファイルに保存しています。 ファイルの内容は次の通りです。 最初の 3 行にはファイルの説明があります。\n\n\n\n\n\n# 6 Sargassum macrocarpum individuals from 2 sites were measured.\n# site: is the collection site (A, B).\n# size: is the width of the individual in mm.\nsite,size\nA,19.9\nA,20.6\nA,20.3\nA,20.4\nA,20.9\nA,18.1\nB,22.3\nB,22.9\nB,22\nB,23.7\nB,20.9\nB,21.7\n\n\nでは、データを R に読み込みます。\n\nfilename = \"./_data/sargassum_t-test_dataset.csv\"\ndset = read_csv(filename)\n\nWarning: One or more parsing issues, see `problems()` for details\n\n\nRows: 15 Columns: 1\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): # 6 Sargassum macrocarpum individuals from 2 sites were measured.\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n読み込んだデータの内容を確認しましょう。\n\ndset\n\n# A tibble: 15 × 1\n   `# 6 Sargassum macrocarpum individuals from 2 sites were measured.`\n   <chr>                                                              \n 1 # site: is the collection site (A, B).                             \n 2 # size: is the width of the individual in mm.                      \n 3 site,size                                                          \n 4 A,19.9                                                             \n 5 A,20.6                                                             \n 6 A,20.3                                                             \n 7 A,20.4                                                             \n 8 A,20.9                                                             \n 9 A,18.1                                                             \n10 B,22.3                                                             \n11 B,22.9                                                             \n12 B,22                                                               \n13 B,23.7                                                             \n14 B,20.9                                                             \n15 B,21.7                                                             \n\n\n説明があるので、読み込みに失敗しました。 読み込んだデータのクラス (class) は 15 行 1 列の tibble になっています。 2 列あるはずです。 この場合、read_csv() に説明を無視させないといけない。\nskip = 3 を read_csv() に渡せば、最初の 3 行をスキップできます。\n\nfilename = \"./_data/sargassum_t-test_dataset.csv\"\ndset = read_csv(filename, skip = 3)\n\nRows: 12 Columns: 2\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): site\ndbl (1): size\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\ndset\n\n# A tibble: 12 × 2\n   site   size\n   <chr> <dbl>\n 1 A      19.9\n 2 A      20.6\n 3 A      20.3\n 4 A      20.4\n 5 A      20.9\n 6 A      18.1\n 7 B      22.3\n 8 B      22.9\n 9 B      22  \n10 B      23.7\n11 B      20.9\n12 B      21.7\n\n\n12 行 2 列の tibble になりました。 列1の列名は site 列２の列名は size です。"
  },
  {
    "objectID": "ttest.html#まずデータの平均値や標準偏差などをもとめる",
    "href": "ttest.html#まずデータの平均値や標準偏差などをもとめる",
    "title": "2群の比較：t 検定",
    "section": "まずデータの平均値や標準偏差などをもとめる",
    "text": "まずデータの平均値や標準偏差などをもとめる\nsite ごとの size の平均値、標準偏差、サンプル数、標準誤差は tidyverse パッケージの解析システムをつかいます。\n\ndset |> \n  group_by(site) |> \n  summarise(across(size, list(mean = mean, sd = sd, n = length))) |> \n  mutate(size_se = size_sd / sqrt(size_n))\n\n# A tibble: 2 × 5\n  site  size_mean size_sd size_n size_se\n  <chr>     <dbl>   <dbl>  <int>   <dbl>\n1 A          20.0   1.00       6   0.410\n2 B          22.2   0.971      6   0.396"
  },
  {
    "objectID": "ttest.html#t-検定-1",
    "href": "ttest.html#t-検定-1",
    "title": "2群の比較：t 検定",
    "section": "t 検定",
    "text": "t 検定\nt検定は t.test() でやります。\n\nt.test(size ~ site, data = dset)\n\n\n    Welch Two Sample t-test\n\ndata:  size by site\nt = -3.8886, df = 9.9893, p-value = 0.003022\nalternative hypothesis: true difference in means between group A and group B is not equal to 0\n95 percent confidence interval:\n -3.486976 -0.946357\nsample estimates:\nmean in group A mean in group B \n       20.03333        22.25000 \n\n\nt.test() の結果をオブジェクトに書き込んだら、t値 (t value)、p値 (p value)、自由度 (degrees of freedom) を抽出できます。\n\ndset_test = t.test(size ~ site, data = dset)\ndset_test$statistic  # t value\n\n        t \n-3.888623 \n\ndset_test$parameter  # degrees of freedom \n\n      df \n9.989348 \n\ndset_test$p.value 　 # p value\n\n[1] 0.003022351"
  },
  {
    "objectID": "ttest.html#結果",
    "href": "ttest.html#結果",
    "title": "2群の比較：t 検定",
    "section": "結果",
    "text": "結果\n\nノコギリモクの幼体において、サイト A から採取した幼体の幅（平均値±標準誤差）は 20.03 ± 0.41 mm でしたが、 サイト B から採取した幼体の幅は 22.25 ± 0.40 mm でした。 ｔ検定の結果、両地点で幼体幅間に有意な差がみられた (t(9.99) = -3.889; P = 0.0030)。\n\n有意水準より低いP値は「P < 0.05」のように書くことも有ります。 つまり、「ｔ検定の結果、両地点で幼体幅間に有意な差がみられた (t(9.99) = -3.889; P < 0.05)」。\nt検定の結果を記述することが重要です。この 3 つの情報を必ず記述しましょう。\n\nt(9.99): 検定に使用した自由度（サンプル数の目安）\n-3.889: t検定の統計量\nP = 0.0030: 結果のP値"
  },
  {
    "objectID": "ttest.html#付録-a-等分散性と正規性の検定",
    "href": "ttest.html#付録-a-等分散性と正規性の検定",
    "title": "2群の比較：t 検定",
    "section": "付録 A: 等分散性と正規性の検定",
    "text": "付録 A: 等分散性と正規性の検定\nデータの正規性と等分散性の検証も必要であれば Levene Test と Shapiro-Wilk Normality Test があります。 Levene Test は car パッケージの leveneTest() 関数でできますが、Shapiro-Wilk Normality Test はベースR に あるので、 パッケージの読み込みは必要ないです。\n等分散性の検定\nLevene Test (ルビーン検定) は2群以上の分散の均質性 (homogeneity) を検定するための検定です。 ルビーン検定の帰無仮説は「各群の分散は等しい」です。 有意水準より低いP値を求めたら、帰無仮説を棄却します。 棄却した場合、各群は均一な分散ではありません。\n\nlibrary(car)\n\nLoading required package: carData\n\n\n\nAttaching package: 'car'\n\n\nThe following object is masked from 'package:dplyr':\n\n    recode\n\n\nThe following object is masked from 'package:purrr':\n\n    some\n\nleveneTest(size ~ site, data = dset)\n\nWarning in leveneTest.default(y = y, group = group, ...): group coerced to\nfactor.\n\n\nLevene's Test for Homogeneity of Variance (center = median)\n      Df F value Pr(>F)\ngroup  1   0.079 0.7844\n      10               \n\n\n\n\nWarning in leveneTest.default(y = y, group = group, ...): group coerced to\nfactor.\n\nWarning in leveneTest.default(y = y, group = group, ...): group coerced to\nfactor.\n\n\nルビーン検定の統計量は F 値です。 データの等分散性を確認したところ、 F(1,10) = 0.08、 P値は P = 0.7844です。 有意水準より大きいので、帰無仮説を棄却しません。 つまり、等分散性ではないといえません。\n正規性の検定\nShapiro-Wilk Normality Test (シャピロ–ウィルク検定) の帰無仮説は「サンプルが正規分布に従う母集団からとれた」です。 つまりシャピロウィルク検定から得たP値はサンプルの正規性を評価する指標です。 帰無仮説検定論の場合、有意水準より低いP値は帰無仮説を棄却することになり、センプルは正規分布に従わない母集団から得たものだと考えられるようになる。\n\nshapiro.test(dset$size)\n\n\n    Shapiro-Wilk normality test\n\ndata:  dset$size\nW = 0.97575, p-value = 0.9608\n\n\n\n\n\nシャピロウィルク検定の統計量は W値です。 W =0.98、 P = ので、 帰無仮説を棄却しません。 正規性に従わないといえません。\n一般的な手順のコード\n\nlibrary(tidyverse)\nlibrary(car)\nfilename = \"./_data/sargassum_t-test_dataset.csv\"\ndset = read_csv(filename, skip = 3)\n\n# (1) データの可視化\nggplot(dset) + \n  geom_point(aes(x = site, y = size)) +\n  labs(y = \"Width (mm)\",\n       x = \"Site\")\n\n# (2) 等分散性の確認\nleveneTest(size ~ site, data = dset)\n\n# (3) 正規性の確認\nshapiro.test(dset$size)\n\n# (4) t検定\nt.test(size ~ site, data = dset)"
  },
  {
    "objectID": "ttest.html#付録-b-本資料のデータ作成",
    "href": "ttest.html#付録-b-本資料のデータ作成",
    "title": "2群の比較：t 検定",
    "section": "付録 B: 本資料のデータ作成",
    "text": "付録 B: 本資料のデータ作成\n資料に使ったデータは次のコードでつくれます。\n\nlibrary(tidyverse)\nset.seed(2021)\nnA = 6\nnB = 6\nmeanA = 20\nmeanB = 22\nsigmaA = 1\nsigmaB = 1\ngroupA = rnorm(nA, meanA, sigmaA) |>  round(digits = 1)\ngroupB = rnorm(nB, meanB, sigmaB) |>  round(digits = 1)\ndset   = tibble(site = c(\"A\", \"B\"), size = list(groupA, groupB)) |>  unnest(size)\nL1 = \"# 6 Sargassum macrocarpum individuals from 2 sites were measured.\"\nL2 = \"# site: is the collection site (A, B).\"\nL3 = \"# size: is the width of the individual in mm.\"\nfname = \"sargassum_t-test_dataset.csv\"\nwrite_lines(file = fname, list(L1, L2, L3))\nwrite_csv(dset, file = fname, append = TRUE, col_names = TRUE)"
  },
  {
    "objectID": "anova.html#ノコギリモク-sargassum-macrocarpum-の疑似データ",
    "href": "anova.html#ノコギリモク-sargassum-macrocarpum-の疑似データ",
    "title": "一元配置分散分析",
    "section": "ノコギリモク (Sargassum macrocarpum) の疑似データ",
    "text": "ノコギリモク (Sargassum macrocarpum) の疑似データ\n\n\n\n\n\n\n\nThe width of the rope is 6 mm, so the juvenile is about 20 mm in width.\n\n\n\n\n\n\n\n\n\n\nTable 1:  Size (mm) of juvenile Sargassum macrocarpum（ノコギリモク）. \n \n  \n    Sample \n    Site A \n    Site B \n    Site C \n  \n \n\n  \n    1 \n    19.9 \n    22.3 \n    18.2 \n  \n  \n    2 \n    20.6 \n    22.9 \n    19.5 \n  \n  \n    3 \n    20.3 \n    22.0 \n    19.6 \n  \n  \n    4 \n    20.4 \n    23.7 \n    16.2 \n  \n  \n    5 \n    20.9 \n    20.9 \n    19.6 \n  \n  \n    6 \n    18.1 \n    21.7 \n    18.1 \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nノコギモクの大きさは Table 1 に示しています。 サンプルは 3 箇所（3群）から採取しました。 各サンプルに個体数番号もふっています。\nデータは 上のノートに紹介したコードで発生しました。"
  },
  {
    "objectID": "anova.html#データの可視化",
    "href": "anova.html#データの可視化",
    "title": "一元配置分散分析",
    "section": "データの可視化",
    "text": "データの可視化\n\nggplot(dset) + \n  geom_point(aes(x = g, y = data, color = g),\n             size = 2,\n             position = position_jitter(0.1)) +\n  scale_color_manual(\"\", values = viridis::viridis(4)) +\n  labs(y = \"Width (mm)\", x = \"Site\") +\n  theme(legend.position = \"top\")\n\n\n\n\n各サイトの平均値 (\\overline{x}), 標準偏差 (s), と標準誤差 (s.e.) は、\n\n\\overline{x}_A= 20; s_A= 1; s.e. = 0.41\n\\overline{x}_B= 22.2; s_B= 0.97; s.e. = 0.4\n\\overline{x}_C= 18.5; s_C= 1.34; s.e. = 0.55"
  },
  {
    "objectID": "anova.html#hypothesis",
    "href": "anova.html#hypothesis",
    "title": "一元配置分散分析",
    "section": "仮説を決める",
    "text": "仮説を決める\n\n\n\n\n\n\nImportant\n\n\n\n解析する前に作業仮説、帰無仮説、対立仮説を設定する必要があります。\n\n\n\n\n\n\n\n\nWorking hypothesis\n\n\n\n作業仮設: ノコギリモクの大きさは採取した場所によって異なる。\n\n\n\n記述統計量によって、平均値以外の統計量（標準偏差と標準誤差）は似ています。\n\\overline{x}_A= 20; s= 1; s.e. = 0.41\n\\overline{x}_B= 22.2; s= 0.97; s.e. = 0.4\n\\overline{x}_C= 18.5; s= 1.34; s.e. = 0.55\n\n\n帰無仮説と対立仮説\n統計学的に解析するための帰無仮説と対立仮説を決めます。\n\nH_0 (null hypothesis 帰無仮説・ヌル仮説): ノコギリモクの大きさは場所によって異ならない\nH_A (alternative hypothesis 対立仮設): ノコギリモクの大きさは場所によって異なる"
  },
  {
    "objectID": "anova.html#ナイーブな-ペア毎の-t-検定",
    "href": "anova.html#ナイーブな-ペア毎の-t-検定",
    "title": "一元配置分散分析",
    "section": "ナイーブな ペア毎の t 検定",
    "text": "ナイーブな ペア毎の t 検定\nとりあえず、場所のペア毎の t 検定を実施します。 このとき、3 つの帰無仮説が必要なので、@hypothesis と違います。\n\nH0,A-B: Site A と Site B の大きさは同じ\nH0,A-C: Site A と Site C の大きさは同じ\nH0,B-C: Site B と Site C の大きさは同じ\n\nでは、それぞれの t 検定を実施します。\n\nSite A and B の t 検定\n\nresultAB = dset |> filter(!str_detect(g, \"C\"))\nresultAB = t.test(data ~ g, data = resultAB)\nresultAB\n\n\n    Welch Two Sample t-test\n\ndata:  data by g\nt = -3.8886, df = 9.9893, p-value = 0.003022\nalternative hypothesis: true difference in means between group A and group B is not equal to 0\n95 percent confidence interval:\n -3.486976 -0.946357\nsample estimates:\nmean in group A mean in group B \n       20.03333        22.25000 \n\n\nt値は -3.889、P値は 0.003 です。 0.003 \\le 0.05 なので、帰無仮説は棄却できます。\n\n\nSite A and C の t 検定\n\nresultAC = dset |> filter(!str_detect(g, \"B\"))\nresultAC = t.test(data ~ g, data = resultAC)\nresultAC\n\n\n    Welch Two Sample t-test\n\ndata:  data by g\nt = 2.1968, df = 9.2717, p-value = 0.05477\nalternative hypothesis: true difference in means between group A and group C is not equal to 0\n95 percent confidence interval:\n -0.03773888  3.03773888\nsample estimates:\nmean in group A mean in group C \n       20.03333        18.53333 \n\n\nt値は 2.197、P値は 0.0548 です。 0.0548 \\ge 0.05 なので、帰無仮説は棄却できません。\n\n\nSite B and C の t 検定\n\nresultBC = dset |> filter(!str_detect(g, \"A\"))\nresultBC = t.test(data ~ g, data = resultBC)\nresultBC\n\n\n    Welch Two Sample t-test\n\ndata:  data by g\nt = 5.5063, df = 9.1228, p-value = 0.0003595\nalternative hypothesis: true difference in means between group B and group C is not equal to 0\n95 percent confidence interval:\n 2.192862 5.240472\nsample estimates:\nmean in group B mean in group C \n       22.25000        18.53333 \n\n\nt値は 5.506、P値は 0.0004 です。 0.0004 \\le 0.05 なので、帰無仮説は棄却できます。\nt検定の結果をまとめました。\n\n\n\n\nTable 2:  Summary of three t-tests. \n \n  \n    Pair \n    Difference \n    t-value \n    P-value \n    d.f. \n    95% CI \n    Is P ≤ 0.05? \n  \n \n\n  \n    B-A \n    -2.216667 \n    -3.888623 \n    0.0030224 \n    9.989348 \n    -3.487 to -0.95 \n    Yes \n  \n  \n    C-A \n    1.500000 \n    2.196821 \n    0.0547748 \n    9.271711 \n    -0.038 to  3.04 \n    No \n  \n  \n    C-B \n    3.716667 \n    5.506257 \n    0.0003595 \n    9.122821 \n    2.193 to  5.24 \n    Yes \n  \n\n\n\n\n\n\nd.f. は Welch-Satterthwaite 式で求めた自由度1、95% CI は 95% 信頼区間です。1 degrees-of-freedom"
  },
  {
    "objectID": "anova.html#第１種の誤り-accepting-a-false-h0",
    "href": "anova.html#第１種の誤り-accepting-a-false-h0",
    "title": "一元配置分散分析",
    "section": "第１種の誤り (accepting a false H0)",
    "text": "第１種の誤り (accepting a false H0)\n\n\n\n\n\n\n第１種の誤り\n\n\n\nH0 が FALSE のときに帰無仮説を棄却できなかった誤りです。\n\n\nt 検定を 1 回実施したときの誤りは\n\n\\text{Type I error rate} = \\alpha = 0.05\n\nt 検定を 2 回実施したときの誤りは\n\n1 - (1 - \\alpha) \\times (1 - \\alpha) = 1 - (1-\\alpha)^2=0.0975\n\nt 検定を 3 回実施したときの誤りは\n\n1 - (1 - \\alpha) \\times (1 - \\alpha) \\times (1 - \\alpha)= 1 - (1-\\alpha)^3=0.142625\n\nt 検定を h 回実施したとき、第１種の誤りは 1 - (1-\\alpha)^h です。\n\n群が増えると大変なことなる\nn 群のサンプルの全ペア毎の比較がしたい場合、 h のペア (k = 2) が存在します。\n\nh = \\binom{n}{k}=\\frac{n!}{k!(n-k!)}\n\nペア毎の h の数を求める式は次のようになります。\n\nh = \\binom{n}{2}=\\frac{n!}{2!(n-2!)} = \\frac{n(n-1)}{2}\n\n例えば、5 site の場合、10 のペアが存在します。 ペア毎の t 検定をしたら、第１種の誤りは\n\n1 - (1-0.05)^{10}=0.4012631\n\n\n\n\n\n\n\nR での求め方\n\n\n\n\nalpha = 0.05       # 有意水準\nk = 2              # ペアだから 2\nn = 5              # 比較する群・場所・グループの数\nh = choose(n, k)   # ペアの数\n1 - (1 - alpha)^h  # 第１種の誤り\n\n[1] 0.4012631\n\n\n\n\n\n\n\n\n\n比較する群が増えると、t 検定を繰り返して実施すると、第１種の誤りを起こしやすい。"
  },
  {
    "objectID": "anova.html#one-way-anova-一元配置分散分析",
    "href": "anova.html#one-way-anova-一元配置分散分析",
    "title": "一元配置分散分析",
    "section": "One-Way ANOVA (一元配置分散分析)",
    "text": "One-Way ANOVA (一元配置分散分析)\n複数群（因子の水準）の解析は 一元配置分散分析)2 用います。2 One-Way ANOVA (One-Way Analysis of Variance\n\n因子・要因3：説明変数、一般的には離散型な変数\n水準4：説明変数における値、レベル、要素\n\n3 factor4 level, factor level分散分析の帰無仮説は、\n\n\\mu_1 = \\mu_2 = \\cdots = \\mu_i\n\nつまり、一つの検定で複数群の平均値を同時に解析するから、第１種の誤りは 0.05 に抑えられる。\n分散分析のモデル式は次のように表せます。\n\nx_{ij} = \\mu_i + \\epsilon_{ij}\n\n水準 i とサンプル j の値は x_{ij}です。 水準 i の平均値は \\mu_i です。 モデルの残渣[residual]または誤差項[error term]は \\epsilon_{ij} です。"
  },
  {
    "objectID": "anova.html#一元配置分散分析表",
    "href": "anova.html#一元配置分散分析表",
    "title": "一元配置分散分析",
    "section": "一元配置分散分析表",
    "text": "一元配置分散分析表\n\n\n\n\n \n  \n    Factor \n    Degrees-of-freedom (df) \n    Sum-of-Squares (SS) \n    Mean-square (MS) \n    F-value \n    P-value \n  \n \n\n  \n    A \n    $df_A = I-1$ \n    $SS_A$ \n    $MS_A = SS_A / df_A$ \n    $MS_A / MS_R$ \n    $qf(1-α, df_A, df_R)$ \n  \n  \n    e \n    $df_R = I(J-1)$ \n    $SS_R$ \n    $MS_R = SS_R / df_R$ \n     \n     \n  \n  \n     \n    $df_T =IJ-1$ \n    $SS_T$ \n     \n     \n     \n  \n\n\n\n\n\n\n因子は A5\n残渣は e6\n水準数は I7\nサンプル数は　J8\n水準間平方和は SS_A9\n残渣平方和は SS_R10\n総平方和は SS_T11\n水準間平均平方は MS_A12\n残渣平均平方は MS_R13\nF値14は MS の比です。\n\n5 factor6 residual7 number of levels8 number of samples9 among levels sum-of-squares (SS)10 residual SS11 total SS12 among levels mean square (MS)13 residual mean square (MS)14 F-value"
  },
  {
    "objectID": "anova.html#平方和の方程式",
    "href": "anova.html#平方和の方程式",
    "title": "一元配置分散分析",
    "section": "平方和の方程式",
    "text": "平方和の方程式\n\n\\underbrace{\\sum_{i=1}^I\\sum_{j=1}^J(x_{ij} - \\overline{\\overline{x}})^2 }_{\\text{総平方和}\\;(SS_T)} =\n\\overbrace{J\\sum_{i=1}^I(\\overline{x}_{i}-\\overline{\\overline{x}})^2}^{\\text{水準間平方和}\\;SS_A} +\n\\underbrace{\\sum_{i=1}^I\\sum_{j=1}^J(x_{ij} - \\overline{x}_i)^2}_{\\text{残渣平方和}\\;SS_R}\n\n標本平均は \\bar{x}_i、総平均は \\bar{\\bar{x}} です。"
  },
  {
    "objectID": "anova.html#decomposing-the-sum-of-squares",
    "href": "anova.html#decomposing-the-sum-of-squares",
    "title": "一元配置分散分析",
    "section": "Decomposing the sum-of-squares",
    "text": "Decomposing the sum-of-squares\n\n\n\n\n\n\n\n\n\n残渣平方和：各サンプルの値は点、グループ毎の平均値は黒線で示しています。黒線から点の縦線は残渣を表しています。\n\n\n\n\n\n\n\n水準間平方和：各グループの平均値は点、総平均は黒線で示しています。黒線から点の縦線はグループ毎の平均値と総平均の違いを表しています。"
  },
  {
    "objectID": "anova.html#分散分析の統計量",
    "href": "anova.html#分散分析の統計量",
    "title": "一元配置分散分析",
    "section": "分散分析の統計量",
    "text": "分散分析の統計量\n\nF = \\left . \\frac{SS_A}{I-1} \\right / \\frac{SS_R}{I(J-1)}  = \\frac{SS_A}{SS_R} \\frac{I(J-1)}{I-1} = \\frac{MS_A}{MS_R}\n\nF値は 自由度 \\text{df}_1 = I-1, \\text{df}_2 = I(J-1) のF分布に従います。 水準の数は I、水準ごとのサンプルの数は J です。\n\n\n\n\n\n\nNote\n\n\n\n\nF値の分子15 が大きとき、または分母16が小さいとき、F値は大きいです。\nF値とP値は反比例します。\n\n15 numerator16 denominator"
  },
  {
    "objectID": "anova.html#f値の確率密度関数",
    "href": "anova.html#f値の確率密度関数",
    "title": "一元配置分散分析",
    "section": "F値の確率密度関数",
    "text": "F値の確率密度関数\n\nP(x|\\text{df}_1, \\text{df}_2) = \\frac{1}{\\mathrm{B}\\left(\\frac{\\text{df}_1}{2}, \\frac{\\text{df}_2}{2}\\right)}\\left(\\frac{\\text{df}_1}{\\text{df}_2}\\right)^{\\left(\\frac{\\text{df}_1}{2}\\right)}x^{\\left(\\frac{\\text{df}_1}{2}-1\\right)}\\left(1+\\frac{\\text{df}_1}{\\text{df}_2}x\\right)^{\\left(-\\frac{\\text{df}_1+\\text{df}_2}{2}\\right)}\n \\mathrm{B}(\\text{df}_1, \\text{df}_2)=\\int_0^1t^{x-1}(1-t)^{y-1}dt は ベータ関数17 といいます。 \\text{df}_1 と \\text{df}_2 は自由度、x は確率変数です。17 Beta function\n\n\n\n\n\n自由度が変わるとF分布の形が変わります。"
  },
  {
    "objectID": "anova.html#一元配置分散分析表の仮定",
    "href": "anova.html#一元配置分散分析表の仮定",
    "title": "一元配置分散分析",
    "section": "一元配置分散分析表の仮定",
    "text": "一元配置分散分析表の仮定\n分散分析するときに注意する仮定\n\n水準毎の母分散は等しい\n残渣は正規分布に従う\n観測値はお互いに独立であり、同一分布に従う\n観測変数は連続変数18\n説明変数は離散変数19\n\n18 continuous19 discrete"
  },
  {
    "objectID": "anova.html#rにおける解析",
    "href": "anova.html#rにおける解析",
    "title": "一元配置分散分析",
    "section": "Rにおける解析",
    "text": "Rにおける解析\n解析例に使うデータは thedata.csv に保存したので、まずは読み込みます。\n\n\n\n\n# Read data from a csv file\ndset = read_csv(\"thedata.csv\")\n\nデータをグループ化したあと、最初の 2 行を表示する。\n\ndset |> group_by(site) |> slice(1:2)\n\n# A tibble: 6 × 2\n# Groups:   site [3]\n  site    obs\n  <fct> <dbl>\n1 A      19.9\n2 A      20.6\n3 B      22.3\n4 B      22.9\n5 C      18.2\n6 C      19.5\n\n\n帰無仮説を当てはめる。\n\nnullmodel = lm(obs ~ 1, data = dset) # 帰無モデル、ヌルモデル\n\nフルモデル（対立仮説）を当てはめる。\n\nfullmodel = lm(obs ~ site, data = dset) # 対立モデル、フルモデル"
  },
  {
    "objectID": "anova.html#分散分析の結果",
    "href": "anova.html#分散分析の結果",
    "title": "一元配置分散分析",
    "section": "分散分析の結果",
    "text": "分散分析の結果\n帰無仮説と対立仮説のモデル結果を用いた方法。\n\nanova(nullmodel, fullmodel, test = \"F\")\n\nAnalysis of Variance Table\n\nModel 1: obs ~ 1\nModel 2: obs ~ site\n  Res.Df    RSS Df Sum of Sq      F    Pr(>F)    \n1     17 60.656                                  \n2     15 18.702  2    41.954 16.825 0.0001471 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\nF値は 16.825、自由度は df1 = 2 と df2 = 15 です。 よって、P値は 0.000147 です。 有意水準が \\alpha = 0.05 、自由度が　(2, 15) のときのF値は 3.682.\nフルモデルの結果でけ用いた解析\n\nanova(fullmodel)\n\nAnalysis of Variance Table\n\nResponse: obs\n          Df Sum Sq Mean Sq F value    Pr(>F)    \nsite       2 41.954 20.9772  16.825 0.0001471 ***\nResiduals 15 18.702  1.2468                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\naov() 関数を用いた方法\nこのとき、lm() は不要です。\n\naovout = aov(obs ~ site, data = dset)\nsummary(aovout)\n\n            Df Sum Sq Mean Sq F value   Pr(>F)    \nsite         2  41.95  20.977   16.82 0.000147 ***\nResiduals   15  18.70   1.247                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\n\n\nImportant\n\n\n\n分散分析の帰無仮説は \\mu_0 = \\mu_1 = \\cdots \\mu_i なので、 ペア間の検定ではないです。"
  },
  {
    "objectID": "anova.html#多重比較-1",
    "href": "anova.html#多重比較-1",
    "title": "一元配置分散分析",
    "section": "多重比較",
    "text": "多重比較\n分散分析の帰無仮説を棄却したら、ペア毎の比較がしたくなります。 第１種の誤りを抑える多重比較の検定は豊富に存在します。\n\nBonferroni Procedure (ボンフェロニ法)\nHolm-Bonferroni Method (ホルム = ボンフェロニ法)\nTukey’s Honest Signiﬁcant Difference Test (テューキーの HSD 検定)\nTukey-Kramer method, Tukey’s test\nScheffe’s Method (シェッフェの方法)\nDunnett’s Test (ダネットの検定)\nFisher’s Least Signiﬁcant Difference (フィッシャーの最小有意差法)\nDuncan’s new multiple range test (ダンカンの新多重範囲検定)\n\n1 から 4 はペア毎の比較です。 ダネットの検定は水準に対する比較です。 フィッシャーとダンカンの検定の第１種の誤りは高いので、使用しないでください。"
  },
  {
    "objectID": "anova.html#多重比較用-r-パッケージ",
    "href": "anova.html#多重比較用-r-パッケージ",
    "title": "一元配置分散分析",
    "section": "多重比較用 R パッケージ",
    "text": "多重比較用 R パッケージ\n多重比較用の関数は次のパッケージにあります。\n\nmultcomp\nemmeans\n\nここでは、emmeans を紹介します。\n\nlibrary(emmeans) # 多重比較用パッケージ\nlibrary(nlme)    # gls() 関数はこのパッケージにある\n\n\nAttaching package: 'nlme'\n\n\nThe following object is masked from 'package:dplyr':\n\n    collapse"
  },
  {
    "objectID": "anova.html#繰り返しウェルチの-t-検定",
    "href": "anova.html#繰り返しウェルチの-t-検定",
    "title": "一元配置分散分析",
    "section": "繰り返しウェルチの t 検定",
    "text": "繰り返しウェルチの t 検定\n説明のために紹介しています。実際の解析には使わないでください。\n\nglsmodel = gls(obs ~ site, data = dset, \n               weights = varIdent(form = ~ 1|site))\nemout = emmeans(glsmodel, specs = pairwise ~ site, adjust = \"none\")\nemout$contrasts |> summary(infer =T)\n\n contrast estimate    SE   df lower.CL upper.CL t.ratio p.value\n A - B       -2.22 0.570 9.99  -3.4870   -0.946  -3.889  0.0030\n A - C        1.50 0.683 9.26  -0.0381    3.038   2.197  0.0548\n B - C        3.72 0.675 9.11   2.1925    5.241   5.506  0.0004\n\nDegrees-of-freedom method: satterthwaite \nConfidence level used: 0.95 \n\n\n第１種の誤りを調整していません。"
  },
  {
    "objectID": "anova.html#繰り返し-t-検定",
    "href": "anova.html#繰り返し-t-検定",
    "title": "一元配置分散分析",
    "section": "繰り返し t 検定",
    "text": "繰り返し t 検定\n説明のために紹介しています。実際の解析には使わないでください。\n\nemout = emmeans(fullmodel, specs = pairwise ~ site, data = dset, adjust = \"none\")\nemout$contrasts |> summary(infer =T)\n\n contrast estimate    SE df lower.CL upper.CL t.ratio p.value\n A - B       -2.22 0.645 15   -3.591   -0.843  -3.438  0.0037\n A - C        1.50 0.645 15    0.126    2.874   2.327  0.0344\n B - C        3.72 0.645 15    2.343    5.091   5.765  <.0001\n\nConfidence level used: 0.95 \n\n\n第１種の誤りを調整していません。"
  },
  {
    "objectID": "anova.html#ボンフェロニ法",
    "href": "anova.html#ボンフェロニ法",
    "title": "一元配置分散分析",
    "section": "ボンフェロニ法",
    "text": "ボンフェロニ法\n\nemout = emmeans(fullmodel, specs = pairwise ~ site, data=dset, adjust = \"bonferroni\")\nemout$contrasts |> summary(infer =T)\n\n contrast estimate    SE df lower.CL upper.CL t.ratio p.value\n A - B       -2.22 0.645 15   -3.953    -0.48  -3.438  0.0110\n A - C        1.50 0.645 15   -0.237     3.24   2.327  0.1032\n B - C        3.72 0.645 15    1.980     5.45   5.765  0.0001\n\nConfidence level used: 0.95 \nConf-level adjustment: bonferroni method for 3 estimates \nP value adjustment: bonferroni method for 3 tests \n\n\nP値は p_{adj} =m\\times p によって求められました."
  },
  {
    "objectID": "anova.html#ホルムボンフェロニ法",
    "href": "anova.html#ホルムボンフェロニ法",
    "title": "一元配置分散分析",
    "section": "ホルム=ボンフェロニ法",
    "text": "ホルム=ボンフェロニ法\n\nemout = emmeans(fullmodel, specs = pairwise ~ site, data=dset, adjust = \"holm\")\nemout$contrasts |> summary(infer =T)\n\n contrast estimate    SE df lower.CL upper.CL t.ratio p.value\n A - B       -2.22 0.645 15   -3.953    -0.48  -3.438  0.0073\n A - C        1.50 0.645 15   -0.237     3.24   2.327  0.0344\n B - C        3.72 0.645 15    1.980     5.45   5.765  0.0001\n\nConfidence level used: 0.95 \nConf-level adjustment: bonferroni method for 3 estimates \nP value adjustment: holm method for 3 tests \n\n\nP値は低い値から高い値へ並べ替えてから、p_{adj} = (m+1-k)\\times p によって求めます。 m は比較の数、 k は比較の指数です。\n\n\n\n\n\n\nNote\n\n\n\nボンフェロニ法とホルム=ボンフェロニ法の P値は次のように求められます。\n\nemout = emmeans(fullmodel, specs = pairwise ~ site, adjust = \"none\")\nx = emout$contrasts  |>  as_tibble()\nx  |>  arrange(p.value)  |> \n  mutate(k = 1:3)  |> mutate(m = n())  |> \n  mutate(p.bonferroni = p.value * m,\n         p.holm = p.value * (m + 1 - k))  |> \n  select(contrast, m, k, starts_with(\"p\"))\n\n# A tibble: 3 × 6\n  contrast     m     k   p.value p.bonferroni   p.holm\n  <chr>    <int> <int>     <dbl>        <dbl>    <dbl>\n1 B - C        3     1 0.0000373     0.000112 0.000112\n2 A - B        3     2 0.00366       0.0110   0.00731 \n3 A - C        3     3 0.0344        0.103    0.0344"
  },
  {
    "objectID": "anova.html#テューキーのhsd法",
    "href": "anova.html#テューキーのhsd法",
    "title": "一元配置分散分析",
    "section": "テューキーのHSD法",
    "text": "テューキーのHSD法\n\nemout = emmeans(fullmodel, specs = pairwise ~ site, data=dset, adjust = \"tukey\")\nemout$contrasts |> summary(infer =T)\n\n contrast estimate    SE df lower.CL upper.CL t.ratio p.value\n A - B       -2.22 0.645 15   -3.891   -0.542  -3.438  0.0096\n A - C        1.50 0.645 15   -0.174    3.174   2.327  0.0826\n B - C        3.72 0.645 15    2.042    5.391   5.765  0.0001\n\nConfidence level used: 0.95 \nConf-level adjustment: tukey method for comparing a family of 3 estimates \nP value adjustment: tukey method for comparing a family of 3 estimates \n\n\nP値はステュデント化範囲の分布21に従います。21 Studentized range distribution"
  },
  {
    "objectID": "anova.html#シェッフェの方法",
    "href": "anova.html#シェッフェの方法",
    "title": "一元配置分散分析",
    "section": "シェッフェの方法",
    "text": "シェッフェの方法\n\nemout = emmeans(fullmodel, specs = pairwise ~ site, data=dset, adjust = \"scheffe\")\nemout$contrasts |> summary(infer =T)\n\n contrast estimate    SE df lower.CL upper.CL t.ratio p.value\n A - B       -2.22 0.645 15   -3.966   -0.467  -3.438  0.0128\n A - C        1.50 0.645 15   -0.249    3.249   2.327  0.0991\n B - C        3.72 0.645 15    1.967    5.466   5.765  0.0002\n\nConfidence level used: 0.95 \nConf-level adjustment: scheffe method with rank 2 \nP value adjustment: scheffe method with rank 2 \n\n\nP値はF分布に従います。"
  },
  {
    "objectID": "anova.html#ダネットの検定",
    "href": "anova.html#ダネットの検定",
    "title": "一元配置分散分析",
    "section": "ダネットの検定",
    "text": "ダネットの検定\n\nemout = emmeans(fullmodel, specs = trt.vs.ctrl ~ site, ref = 2)\nemout$contrasts |> summary(infer =T)\n\n contrast estimate    SE df lower.CL upper.CL t.ratio p.value\n A - B       -2.22 0.645 15     -3.8   -0.633  -3.438  0.0070\n C - B       -3.72 0.645 15     -5.3   -2.133  -5.765  0.0001\n\nConfidence level used: 0.95 \nConf-level adjustment: dunnettx method for 2 estimates \nP value adjustment: dunnettx method for 2 tests \n\n\nダネットの検定は、各水準は標準水準と比較する方法です。 P値は多変量 t 分布に従います。"
  },
  {
    "objectID": "anova.html#多重比較のおすすめ",
    "href": "anova.html#多重比較のおすすめ",
    "title": "一元配置分散分析",
    "section": "多重比較のおすすめ",
    "text": "多重比較のおすすめ\n\n比較: A – B, A – C, B – C  テューキーのHSD法\n比較: A – B, A – C, A – D  ダネット法"
  },
  {
    "objectID": "anova2.html",
    "href": "anova2.html",
    "title": "多数群の比較：二元配置分散分析",
    "section": "",
    "text": "二元配置分散分析 (Two-Way ANOVA) 2 種類の因子（要因）を同時に比較するときに使用する。\n二元配置分散分析の帰無仮説\nフルモデルは:\nx_{ijk} = \\mu_{Ai}+\\mu_{Bj} + \\mu_{ABij} + \\epsilon_{ijk}\n水準 i, j, とサンプル k の値は x_{ijk}。 因子 A の水準 i ごとの平均値は \\mu_{Ai}。 因子 B の水準 i ごとの平均値は \\mu_{Bi}。\n交互作用 AB の i,j 効果の平均値は \\mu_{ABij}。 残渣（誤差項）は \\epsilon_{ijk}。"
  },
  {
    "objectID": "anova2.html#two-way-anova-table-二元配置分散分析表",
    "href": "anova2.html#two-way-anova-table-二元配置分散分析表",
    "title": "多数群の比較：二元配置分散分析",
    "section": "Two-Way ANOVA Table (二元配置分散分析表)",
    "text": "Two-Way ANOVA Table (二元配置分散分析表)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFactor\nDegrees-of-freedom (df)\nSum-of-Squares (SS)\nMean-square (MS)\nF-value\nP-value\n\n\n\n\nA\ndf_A = I-1\nSS_A\nMS_A = SS_A / df_A\nMS_A / MS_R\nqf(1-\\alpha, df_A, df_R)\n\n\nB\ndf_B = J-1\nSS_B\nMS_B = SS_B / df_B\nMS_B / MS_R\nqf(1-\\alpha, df_B, df_R)\n\n\nAB\ndf_{AB} = (I-1)(J-1)\nSS_{AB}\nMS_{AB} = SS_{AB} / df_{AB}\nMS_{AB} / MS_R\nqf(1-\\alpha, df_{AB}, df_R)\n\n\ne\ndf_R = IJ(K-1)\nSS_R\nMS_R = SS_R / df_R\n\n\n\n\n\ndf_T = IJK-1\nSS_T\n\n\n\n\n\n\n\n\n\nA と B は主効果、 e は残渣、 I と J は各因子の水準、 K はサンプル数です。 SS_A と SS_B は水準間平方和、 SS_{AB} は相互作用平方和、 SS_R は残渣平方和、 SS_T は総平方和です。 MS_A と MS_B は水準間平均平方、 MS_{AB} は相互作用平均平方、 MS_R は残渣平均平方です。 平均平方の比率はF値です。\n\n\n\n\n\n\n平方和は他にもある\n\n\n\n上述した分散分析表は Type I 平方和 (SS) を求めています。 このとき、SS(A), SS(B|A), SS(AB|A,B) です。 分散分析の結果は因子に順序とに依存し、非釣り合い型データに合わない。\nType II 平方和は、SS(A|B) と SS(B|A) のみです。相互作用はありません。 分散分析の結果は因子に順序とに依存しないが、非釣り合い型データに合わない。\nType III 平方和は、SS(A|B, AB), SS(B|A, AB), SS(AB|A,B) です。 分散分析の結果は因子に順序とに依存しない、非釣り合い型データにも使えるが、 必ずcontr.sum を設定しなければならない。\n\n\n平方和の非釣り合い型データの問題については、Hector, Felten, and Schmid (2010), Langsrud (2003) を参考にしてください。\n\nHector, Andy, Stefanie von Felten, and Bernhard Schmid. 2010. “Analysis of variance with unbalanced data: An update for ecology & evolution.” Journal of Animal Ecology 79: 308–16. https://doi.org/10.1111/j.1365-2656.2009.01634.x.\n\nLangsrud, Øyvind. 2003. “ANOVA for unbalanced data: Use Type II instead.” Statistics and Computing 13: 163–67. https://doi.org/10.1023/A:1023260610025."
  },
  {
    "objectID": "anova2.html#type-i-平方和の方程式",
    "href": "anova2.html#type-i-平方和の方程式",
    "title": "多数群の比較：二元配置分散分析",
    "section": "Type I 平方和の方程式",
    "text": "Type I 平方和の方程式\n\n\\begin{split}\n\\overbrace{\\sum_{i=1}^I\\sum_{j=1}^J\\sum_{k=1}^K(x_{ijk} - \\overline{\\overline{x}})^2 }^{\\text{総平方和}\\;(SS_T)} =\n\\overbrace{JK\\sum_{i=1}^I(\\overline{x}_{i}-\\overline{\\overline{x}})^2}^{\\text{水準間平方和}\\;SS_A} +\n\\overbrace{IK\\sum_{j=1}^J(\\overline{x}_{j}-\\overline{\\overline{x}})^2}^{\\text{水準間平方和}\\;SS_B} \\\\ +\n\\underbrace{K\\sum_{i=1}^I\\sum_{j=1}^J(\\overline{x}_{ij} + \\overline{\\overline{x}})^2}_{\\text{相互作用平方和}\\;SS_{AB}} +\n\\underbrace{\\sum_{i=1}^I\\sum_{j=1}^J\\sum_{k=1}^K(x_{ijk} - \\overline{x}_{ij})^2}_{\\text{残渣平方和}\\;SS_R}\n\\end{split}\n\n\\bar{x}_i is the sample mean (標本平均) and \\bar{\\bar{x}} is the global mean (総平均)."
  },
  {
    "objectID": "anova2.html#二元配置分散分析",
    "href": "anova2.html#二元配置分散分析",
    "title": "多数群の比較：二元配置分散分析",
    "section": "二元配置分散分析",
    "text": "二元配置分散分析\n分散分析の結果。\n\nfullmodel_treatment = lm(Weight ~ pH + Calluna + pH:Calluna, data = festuca)\nanova(fullmodel_treatment)\n\nAnalysis of Variance Table\n\nResponse: Weight\n           Df  Sum Sq Mean Sq F value     Pr(>F)    \npH          1 19.9800 19.9800 28.1792 0.00007065 ***\nCalluna     1 10.2102 10.2102 14.4001    0.00159 ** \npH:Calluna  1  5.3976  5.3976  7.6126    0.01397 *  \nResiduals  16 11.3446  0.7090                       \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nモデル係数の結果。\n\nsummary(fullmodel_treatment)\n\n\nCall:\nlm(formula = Weight ~ pH + Calluna + pH:Calluna, data = festuca)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-1.156 -0.603 -0.138  0.732  1.272 \n\nCoefficients:\n                       Estimate Std. Error t value    Pr(>|t|)    \n(Intercept)              3.3680     0.3766   8.944 0.000000127 ***\npHpH5.5                  3.0380     0.5326   5.705 0.000032562 ***\nCallunaPresent          -0.3900     0.5326  -0.732       0.475    \npHpH5.5:CallunaPresent  -2.0780     0.7531  -2.759       0.014 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.842 on 16 degrees of freedom\nMultiple R-squared:  0.7583,    Adjusted R-squared:  0.713 \nF-statistic: 16.73 on 3 and 16 DF,  p-value: 0.00003447\n\n\n因子ごとの比較は emmeans パッケージの emmeans() 関数でします。 object 引数に、処理するモデルを渡します。 formula には、A因子 と B因子をモデル式として、渡します。\n\nemmip(object = fullmodel_treatment, \n      formula = pH ~ Calluna)\n\n\n\n\n図で確認したと、ペアごとの比較をして、t値を求めます。 object 引数に、処理するモデルを渡します。\nB因子の水準内のペアごとの比較をしたい場合は、specs に pairwise ~ A因子 | B因子 を渡します。\n\nemmeans(object = fullmodel_treatment, specs = pairwise ~ pH | Calluna)\n\n$emmeans\nCalluna = Absent:\n pH    emmean    SE df lower.CL upper.CL\n pH3.5   3.37 0.377 16     2.57     4.17\n pH5.5   6.41 0.377 16     5.61     7.20\n\nCalluna = Present:\n pH    emmean    SE df lower.CL upper.CL\n pH3.5   2.98 0.377 16     2.18     3.78\n pH5.5   3.94 0.377 16     3.14     4.74\n\nConfidence level used: 0.95 \n\n$contrasts\nCalluna = Absent:\n contrast      estimate    SE df t.ratio p.value\n pH3.5 - pH5.5    -3.04 0.533 16  -5.705  <.0001\n\nCalluna = Present:\n contrast      estimate    SE df t.ratio p.value\n pH3.5 - pH5.5    -0.96 0.533 16  -1.803  0.0903\n\n\n全ペア毎の比較は、次の通りです。\n\nemmeans(object = fullmodel_treatment, specs = pairwise ~ pH : Calluna, adjust = \"tukey\") |> \n  summary(infer = T)\n\n$emmeans\n pH    Calluna emmean    SE df lower.CL upper.CL t.ratio p.value\n pH3.5 Absent    3.37 0.377 16     2.57     4.17   8.944  <.0001\n pH5.5 Absent    6.41 0.377 16     5.61     7.20  17.011  <.0001\n pH3.5 Present   2.98 0.377 16     2.18     3.78   7.908  <.0001\n pH5.5 Present   3.94 0.377 16     3.14     4.74  10.457  <.0001\n\nConfidence level used: 0.95 \n\n$contrasts\n contrast                      estimate    SE df lower.CL upper.CL t.ratio\n pH3.5 Absent - pH5.5 Absent      -3.04 0.533 16   -4.562   -1.514  -5.705\n pH3.5 Absent - pH3.5 Present      0.39 0.533 16   -1.134    1.914   0.732\n pH3.5 Absent - pH5.5 Present     -0.57 0.533 16   -2.094    0.954  -1.070\n pH5.5 Absent - pH3.5 Present      3.43 0.533 16    1.904    4.952   6.437\n pH5.5 Absent - pH5.5 Present      2.47 0.533 16    0.944    3.992   4.634\n pH3.5 Present - pH5.5 Present    -0.96 0.533 16   -2.484    0.564  -1.803\n p.value\n  0.0002\n  0.8827\n  0.7118\n  <.0001\n  0.0014\n  0.3080\n\nConfidence level used: 0.95 \nConf-level adjustment: tukey method for comparing a family of 4 estimates \nP value adjustment: tukey method for comparing a family of 4 estimates"
  },
  {
    "objectID": "anova2.html#釣り合い型データと直交性について",
    "href": "anova2.html#釣り合い型データと直交性について",
    "title": "多数群の比較：二元配置分散分析",
    "section": "釣り合い型データと直交性について",
    "text": "釣り合い型データと直交性について\n\n\n\n\n\n\n釣り合い型データ (balanced data)\n\n\n\n各因子水準のデータ数は同じであること\n\n\n\n\n\n\n\n\n直行性 (orthogonality)\n\n\n\n説明変数同士の内積 (inner product) はゼロと意味します。 ベクトルとした場合、ベクトル間の角度が 90°であること。 つまり、説明変数がお互いに相関していないこと。\n\n# Example of calculating the inner product of two 3d vectors.\n#| echo: false\n#| eval: false\nk  = c(rnorm(3))\nx1 = c(rnorm(2),0)\nx1 = x1 - as.vector(x1 %*% k) * k / sqrt(sum(k^2))^2\nx2 = pracma::cross(k,x1)\n\n\nggplot() +\n  geom_segment(aes(x = 0, y = 0, xend = 1, yend = 1)) +\n  geom_segment(aes(x = 0, y = 0, xend = -1, yend = 1)) +\n  geom_text(aes(x = 1, y =1, label = \"(1,1)\"), vjust = 0) +\n  geom_text(aes(x = -1, y =1, label = \"(-1,1)\"), vjust = 0) +\n  geom_label(aes(x = 0, y = sqrt(2*(0.5^2)), label = \"90°\")) +\n  geom_curve(aes(x = 0.5, y = 0.5, xend = -0.5, yend = 0.5),\n             arrow = arrow(ends = \"both\", type = \"closed\")) +\n  scale_x_continuous(expand = expansion(add = 0.2)) +\n  scale_y_continuous(expand = expansion(add = 0.2)) +\n  coord_equal()\n\n\n\n\n著効性のあるベクトルのペア\n\n\n\n\n説明変数の係数 x_1 と x_2 の内積がゼロになること。\n\n\\begin{aligned}\nx_1 &= \\begin{bmatrix}\n-1 & 1\n\\end{bmatrix} \\\\\nx_2 &= \\begin{bmatrix}\n1 & 1\n\\end{bmatrix}\n\\end{aligned}\n\n\nx_1^T \\cdot x_2 = \\begin{bmatrix}\n-1 & 1\n\\end{bmatrix}\n\\begin{bmatrix}\n1 \\\\ 1\n\\end{bmatrix} = (-1 \\times 1) + (1 \\times 1) = 0\n\n\n\n\n\n`summarise()` has grouped output by 'pH'. You can override using the `.groups`\nargument.\n`summarise()` has grouped output by 'name'. You can override using the\n`.groups` argument.\n\n\n\n\n\n\n\n釣り合い型データではないとき、Type-I 平方和を用いたとき,　第2種の誤りを起こすことが高くなります。つまり、誤って帰無仮説を採択することが増えます。\n\n\n\n\nつまり、因子の水準毎のデータ数が異なるとき、係数のデフォルト比 (contr.treatment) と デフォルトの平方和 (Type-I) の解析は誤りです。\n\n\n`summarise()` has grouped output by 'pH'. You can override using the `.groups`\nargument.\n\n\n解析用のデータ数の内訳。\n\ndset |> \n  group_by(pH, Calluna) |> \n  summarise(N = length(Weight))\n\n`summarise()` has grouped output by 'pH'. You can override using the `.groups`\nargument.\n\n\n# A tibble: 4 × 3\n# Groups:   pH [2]\n  pH    Calluna     N\n  <fct> <fct>   <int>\n1 pH3.5 Absent      7\n2 pH3.5 Present     8\n3 pH5.5 Absent     12\n4 pH5.5 Present    14\n\n\nデフォルトの平方和と比較の場合、モデルに入れる因子の順序によってF値が変わります。\n\ncontrasts(dset$pH) = contr.treatment      # Required\ncontrasts(dset$Calluna) = contr.treatment\n# pH first, Calluna second.\nf1 = lm(Weight ~ pH * Calluna, data = dset)\n# Calluna first, pH second.\nf2 = lm(Weight ~ Calluna*pH, data = dset)\nanova(f1)\n\nAnalysis of Variance Table\n\nResponse: Weight\n           Df Sum Sq Mean Sq F value    Pr(>F)    \npH          1 39.924  39.924 102.720 3.178e-12 ***\nCalluna     1 26.948  26.948  69.334 5.252e-10 ***\npH:Calluna  1  8.193   8.193  21.081 4.947e-05 ***\nResiduals  37 14.381   0.389                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nanova(f2)\n\nAnalysis of Variance Table\n\nResponse: Weight\n           Df Sum Sq Mean Sq F value    Pr(>F)    \nCalluna     1 26.623  26.623  68.498 6.089e-10 ***\npH          1 40.248  40.248 103.555 2.844e-12 ***\nCalluna:pH  1  8.193   8.193  21.081 4.947e-05 ***\nResiduals  37 14.381   0.389                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nデータ数が異なるとき、因子は直交ではないときは、Type-III 平方を使いましょう。"
  },
  {
    "objectID": "anova2.html#type-iiii-平方和の分散分析",
    "href": "anova2.html#type-iiii-平方和の分散分析",
    "title": "多数群の比較：二元配置分散分析",
    "section": "Type-IIII 平方和の分散分析",
    "text": "Type-IIII 平方和の分散分析\nType-I 以外の平方を使うとき、car パッケージが必要です。\n\nlibrary(car)\n\nLoading required package: carData\n\n\n\nAttaching package: 'car'\n\n\nThe following object is masked from 'package:dplyr':\n\n    recode\n\n\nThe following object is masked from 'package:purrr':\n\n    some\n\n\nさらに、比較は 必ず contr.sum にすること。\n\ncontrasts(dset$pH) = contr.sum      # Required\ncontrasts(dset$Calluna) = contr.sum # Required\n\n\nfullmodel_1 = lm(Weight ~ pH * Calluna, data = dset)\nfullmodel_2 = lm(Weight ~ Calluna * pH, data = dset)\n\n\nAnova(fullmodel_1, type = \"III\")\n\nAnova Table (Type III tests)\n\nResponse: Weight\n            Sum Sq Df  F value    Pr(>F)    \n(Intercept) 683.36  1 1758.218 < 2.2e-16 ***\npH           42.64  1  109.711 1.278e-12 ***\nCalluna      17.94  1   46.163 5.336e-08 ***\npH:Calluna    8.19  1   21.081 4.947e-05 ***\nResiduals    14.38 37                       \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nAnova(fullmodel_2, type = \"III\")\n\nAnova Table (Type III tests)\n\nResponse: Weight\n            Sum Sq Df  F value    Pr(>F)    \n(Intercept) 683.36  1 1758.218 < 2.2e-16 ***\nCalluna      17.94  1   46.163 5.336e-08 ***\npH           42.64  1  109.711 1.278e-12 ***\nCalluna:pH    8.19  1   21.081 4.947e-05 ***\nResiduals    14.38 37                       \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nモデルに入れる因子の順序が変わっても、結果は同じです。"
  }
]